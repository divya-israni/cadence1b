{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Assisted Recruitment System\n",
    "\n",
    "This notebook implements an AI-powered recruitment system that matches job postings with resumes using natural language processing and machine learning techniques.\n",
    "\n",
    "## Features:\n",
    "- Job posting analysis and cleaning\n",
    "- Resume parsing and skill extraction\n",
    "- Intelligent job-resume matching\n",
    "- Scoring and ranking system\n",
    "- Interactive matching interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dependencies and configuration for the AI recruitment system.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    BERT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    BERT_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from flask import Flask, request, jsonify\n",
    "    from flask_cors import CORS\n",
    "    FLASK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    FLASK_AVAILABLE = False\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    DATABASE_AVAILABLE\n",
    "except NameError:\n",
    "    DATABASE_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded - Jobs: (19001, 24), Resumes: (2484, 4), Cleaned: (32481, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load job postings, resumes, and cleaned datasets.\n",
    "\"\"\"\n",
    "df_jobs = pd.read_csv('Dataset/data job posts.csv')\n",
    "df_resumes = pd.read_csv('Dataset/Resume.csv')\n",
    "df_cleaned = pd.read_csv('Dataset/updated_data_final_cleaned.csv')\n",
    "\n",
    "print(f\"Datasets loaded - Jobs: {df_jobs.shape}, Resumes: {df_resumes.shape}, Cleaned: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Posts: (19001, 24)\n",
      "Missing values: 137017\n",
      "\n",
      "Sample records:\n",
      "                                                      Title  \\\n",
      "0                                   Chief Financial Officer   \n",
      "1  Full-time Community Connections Intern (paid internship)   \n",
      "2                                       Country Coordinator   \n",
      "\n",
      "                                           Company  \\\n",
      "0             AMERIA Investment Consulting Company   \n",
      "1  International Research & Exchanges Board (IREX)   \n",
      "2        Caucasus Environmental NGO Network (CENN)   \n",
      "\n",
      "                                                                                              Location  \n",
      "0                                                                                     Yerevan, Armenia  \n",
      "1  IREX Armenia Main Office; Yerevan, Armenia \\r\\nDESCRIPTION:   IREX currently seeks to fill the p...  \n",
      "2                                                                                     Yerevan, Armenia  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Explore job postings dataset structure and sample records.\n",
    "\"\"\"\n",
    "if df_jobs is not None:\n",
    "    print(f\"Job Posts: {df_jobs.shape}\")\n",
    "    print(f\"Missing values: {df_jobs.isnull().sum().sum()}\")\n",
    "    print(\"\\nSample records:\")\n",
    "    print(df_jobs[['Title', 'Company', 'Location']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume Dataset: (2484, 4)\n",
      "\n",
      "Missing values: 0\n",
      "\n",
      "Resume categories (24):\n",
      "Category\n",
      "INFORMATION-TECHNOLOGY    120\n",
      "BUSINESS-DEVELOPMENT      120\n",
      "FINANCE                   118\n",
      "ADVOCATE                  118\n",
      "ACCOUNTANT                118\n",
      "ENGINEERING               118\n",
      "CHEF                      118\n",
      "AVIATION                  117\n",
      "FITNESS                   117\n",
      "SALES                     116\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Cu...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS       Summary     Versatile  media professional with ba...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 20 years experience in recruiting,   15 plus years ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  \\\n",
       "0  16852973   \n",
       "1  22323967   \n",
       "2  33176873   \n",
       "\n",
       "                                                                                            Resume_str  \\\n",
       "0           HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Cu...   \n",
       "1           HR SPECIALIST, US HR OPERATIONS       Summary     Versatile  media professional with ba...   \n",
       "2           HR DIRECTOR       Summary      Over 20 years experience in recruiting,   15 plus years ...   \n",
       "\n",
       "                                                                                           Resume_html  \\\n",
       "0  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "1  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "2  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "\n",
       "  Category  \n",
       "0       HR  \n",
       "1       HR  \n",
       "2       HR  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Explore resume dataset structure, categories, and sample records.\n",
    "\"\"\"\n",
    "print(f\"Resume Dataset: {df_resumes.shape}\")\n",
    "print(f\"\\nMissing values: {df_resumes.isnull().sum().sum()}\")\n",
    "print(f\"\\nResume categories ({df_resumes['Category'].nunique()}):\")\n",
    "print(df_resumes['Category'].value_counts().head(10))\n",
    "df_resumes.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize spaCy NLP model for text processing and skill extraction.\n",
    "\"\"\"\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"spaCy model not found. Install with: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT models initialized on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa models initialized on cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize BERT and RoBERTa models for semantic text matching and similarity computation.\n",
    "\"\"\"\n",
    "if BERT_AVAILABLE:\n",
    "    try:\n",
    "        bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        bert_model_direct = AutoModel.from_pretrained('bert-base-uncased')\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bert_model_direct.to(device)\n",
    "        print(f\"BERT models initialized on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"BERT initialization failed: {e}\")\n",
    "        bert_model = bert_tokenizer = bert_model_direct = None\n",
    "else:\n",
    "    bert_model = bert_tokenizer = bert_model_direct = None\n",
    "\n",
    "if BERT_AVAILABLE:\n",
    "    try:\n",
    "        roberta_model = SentenceTransformer('all-distilroberta-v1')\n",
    "        roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "        roberta_model_direct = AutoModel.from_pretrained('roberta-base')\n",
    "        roberta_model_direct.to(device)\n",
    "        print(f\"RoBERTa models initialized on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa initialization failed: {e}\")\n",
    "        roberta_model = roberta_tokenizer = roberta_model_direct = None\n",
    "else:\n",
    "    roberta_model = roberta_tokenizer = roberta_model_direct = None\n",
    "\n",
    "def get_bert_embeddings(texts, model_type='sentence_transformer'):\n",
    "    \"\"\"\n",
    "    Generate BERT embeddings for input texts.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of text strings or single text string\n",
    "        model_type: Type of model to use ('sentence_transformer')\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or not texts:\n",
    "        return np.array([])\n",
    "    \n",
    "    try:\n",
    "        if model_type == 'sentence_transformer' and bert_model:\n",
    "            return bert_model.encode(texts, convert_to_tensor=False)\n",
    "        return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"BERT embedding error: {e}\")\n",
    "        return np.array([])\n",
    "\n",
    "def calculate_bert_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity between two text strings using BERT embeddings.\n",
    "    \n",
    "    Args:\n",
    "        text1: First text string\n",
    "        text2: Second text string\n",
    "    \n",
    "    Returns:\n",
    "        Similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or not bert_model:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        embeddings = bert_model.encode([text1, text2])\n",
    "        return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_roberta_similarity(text1, text2):\n",
    "    \"\"\"\n",
    "    Compute semantic similarity between two text strings using RoBERTa embeddings.\n",
    "    \n",
    "    Args:\n",
    "        text1: First text string\n",
    "        text2: Second text string\n",
    "    \n",
    "    Returns:\n",
    "        Similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or not roberta_model:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        embeddings = roberta_model.encode([text1, text2])\n",
    "        return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def extract_skills_bert(text, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Extract relevant skills from text using BERT semantic matching.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to analyze\n",
    "        threshold: Minimum similarity threshold for skill matching\n",
    "    \n",
    "    Returns:\n",
    "        List of extracted skill keywords\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or not text:\n",
    "        return []\n",
    "    \n",
    "    skill_keywords = [\n",
    "        'python', 'java', 'javascript', 'react', 'angular', 'vue', 'node.js',\n",
    "        'machine learning', 'deep learning', 'artificial intelligence', 'ai',\n",
    "        'data science', 'data analysis', 'statistics', 'sql', 'database',\n",
    "        'aws', 'azure', 'docker', 'kubernetes', 'git', 'github',\n",
    "        'project management', 'agile', 'scrum', 'leadership', 'communication',\n",
    "        'marketing', 'sales', 'finance', 'accounting', 'human resources',\n",
    "        'design', 'ui', 'ux', 'photoshop', 'illustrator', 'figma',\n",
    "        'mobile development', 'ios', 'android', 'swift', 'kotlin',\n",
    "        'web development', 'frontend', 'backend', 'full stack', 'devops'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        extracted_skills = []\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for skill in skill_keywords:\n",
    "            similarity = calculate_bert_similarity(text_lower, skill)\n",
    "            if similarity >= threshold:\n",
    "                extracted_skills.append(skill)\n",
    "        \n",
    "        return list(set(extracted_skills))\n",
    "    except Exception as e:\n",
    "        print(f\"BERT skill extraction error: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configure caching system for preprocessed data to improve performance.\n",
    "\"\"\"\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CACHE_JOBS = CACHE_DIR / \"df_jobs_clean.pkl\"\n",
    "CACHE_RESUMES = CACHE_DIR / \"df_resumes_clean.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT and RoBERTa-based matching functions for semantic job-resume matching.\n",
    "\"\"\"\n",
    "def find_best_matches_bert(job_index, df_jobs, df_resumes, top_n=5):\n",
    "    \"\"\"\n",
    "    Find top matching resumes for a job using BERT semantic embeddings.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of the job in df_jobs\n",
    "        df_jobs: DataFrame of job postings with 'CleanText' column\n",
    "        df_resumes: DataFrame of resumes with 'CleanText' column\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked matches and similarity scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job_text = df_jobs.iloc[job_index]['CleanText']\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        \n",
    "        job_embedding = bert_model.encode([job_text])\n",
    "        resume_embeddings = bert_model.encode(resume_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': df_resumes.iloc[idx]['ID'],\n",
    "                'Category': df_resumes.iloc[idx]['Category'],\n",
    "                'BERT_Similarity_Score': similarities[idx],\n",
    "                'Resume_Text': df_resumes.iloc[idx]['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def enhanced_matching_bert(job_index, df_jobs, df_resumes, top_n=5, skill_weight=0.3, bert_weight=0.7):\n",
    "    \"\"\"\n",
    "    Enhanced matching combining BERT semantic similarity with skill overlap.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of the job in df_jobs\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        top_n: Number of top matches to return\n",
    "        skill_weight: Weight for skill overlap score (default 0.3)\n",
    "        bert_weight: Weight for BERT similarity score (default 0.7)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked matches and combined scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job = df_jobs.iloc[job_index]\n",
    "        job_text = job['CleanText']\n",
    "        job_skills = set(job['Skills']) if job['Skills'] else set()\n",
    "        \n",
    "        job_embedding = bert_model.encode([job_text])\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        resume_embeddings = bert_model.encode(resume_texts)\n",
    "        \n",
    "        bert_similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        \n",
    "        skill_scores = []\n",
    "        for idx, resume in df_resumes.iterrows():\n",
    "            resume_skills = set(resume['Skills']) if resume['Skills'] else set()\n",
    "            \n",
    "            if job_skills and resume_skills:\n",
    "                overlap = len(job_skills.intersection(resume_skills))\n",
    "                skill_score = overlap / len(job_skills) if job_skills else 0\n",
    "            else:\n",
    "                skill_score = 0\n",
    "            \n",
    "            skill_scores.append(skill_score)\n",
    "        \n",
    "        combined_scores = bert_weight * bert_similarities + skill_weight * np.array(skill_scores)\n",
    "        top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            resume = df_resumes.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': resume['ID'],\n",
    "                'Category': resume['Category'],\n",
    "                'BERT_Similarity_Score': bert_similarities[idx],\n",
    "                'Skill_Overlap_Score': skill_scores[idx],\n",
    "                'Combined_Score': combined_scores[idx],\n",
    "                'Resume_Text': resume['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def search_jobs_by_keywords_bert(keywords, df_jobs, top_n=5):\n",
    "    \"\"\"\n",
    "    Search for jobs using BERT semantic matching on keyword queries.\n",
    "    \n",
    "    Args:\n",
    "        keywords: Search query string\n",
    "        df_jobs: DataFrame of job postings\n",
    "        top_n: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        clean_keywords = clean_text(keywords)\n",
    "        keyword_embedding = bert_model.encode([clean_keywords])\n",
    "        job_texts = df_jobs['CleanText'].tolist()\n",
    "        job_embeddings = bert_model.encode(job_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(keyword_embedding, job_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job['Company'],\n",
    "                'Location': job['Location'],\n",
    "                'BERT_Similarity_Score': similarities[idx],\n",
    "                'Description': job['JobDescription'][:200] + '...' if pd.notna(job['JobDescription']) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT job search error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def find_best_matches_roberta(job_index, df_jobs, df_resumes, top_n=5):\n",
    "    \"\"\"\n",
    "    Find top matching resumes for a job using RoBERTa semantic embeddings.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of the job in df_jobs\n",
    "        df_jobs: DataFrame of job postings with 'CleanText' column\n",
    "        df_resumes: DataFrame of resumes with 'CleanText' column\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked matches and similarity scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or roberta_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job_text = df_jobs.iloc[job_index]['CleanText']\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        \n",
    "        job_embedding = roberta_model.encode([job_text])\n",
    "        resume_embeddings = roberta_model.encode(resume_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': df_resumes.iloc[idx]['ID'],\n",
    "                'Category': df_resumes.iloc[idx]['Category'],\n",
    "                'RoBERTa_Similarity_Score': similarities[idx],\n",
    "                'Resume_Text': df_resumes.iloc[idx]['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def enhanced_matching_roberta(job_index, df_jobs, df_resumes, top_n=5, skill_weight=0.3, roberta_weight=0.7):\n",
    "    \"\"\"\n",
    "    Enhanced matching combining RoBERTa semantic similarity with skill overlap.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of the job in df_jobs\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        top_n: Number of top matches to return\n",
    "        skill_weight: Weight for skill overlap score (default 0.3)\n",
    "        roberta_weight: Weight for RoBERTa similarity score (default 0.7)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked matches and combined scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or roberta_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job = df_jobs.iloc[job_index]\n",
    "        job_text = job['CleanText']\n",
    "        job_skills = set(job['Skills']) if job['Skills'] else set()\n",
    "        \n",
    "        job_embedding = roberta_model.encode([job_text])\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        resume_embeddings = roberta_model.encode(resume_texts)\n",
    "        \n",
    "        roberta_similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        \n",
    "        skill_scores = []\n",
    "        for idx, resume in df_resumes.iterrows():\n",
    "            resume_skills = set(resume['Skills']) if resume['Skills'] else set()\n",
    "            \n",
    "            if job_skills and resume_skills:\n",
    "                overlap = len(job_skills.intersection(resume_skills))\n",
    "                skill_score = overlap / len(job_skills) if job_skills else 0\n",
    "            else:\n",
    "                skill_score = 0\n",
    "            \n",
    "            skill_scores.append(skill_score)\n",
    "        \n",
    "        combined_scores = roberta_weight * roberta_similarities + skill_weight * np.array(skill_scores)\n",
    "        top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            resume = df_resumes.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': resume['ID'],\n",
    "                'Category': resume['Category'],\n",
    "                'RoBERTa_Similarity_Score': roberta_similarities[idx],\n",
    "                'Skill_Overlap_Score': skill_scores[idx],\n",
    "                'Combined_Score': combined_scores[idx],\n",
    "                'Resume_Text': resume['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced RoBERTa matching error: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Text preprocessing and TF-IDF matching functions.\n",
    "\"\"\"\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and normalize text by removing HTML, special characters, and normalizing whitespace.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw text string\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned lowercase text string\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_skills(text, nlp_model):\n",
    "    \"\"\"\n",
    "    Extract skill keywords from text using spaCy NLP model.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to analyze\n",
    "        nlp_model: spaCy language model\n",
    "    \n",
    "    Returns:\n",
    "        List of unique skill keywords\n",
    "    \"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return []\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    skills = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.pos_ in ['NOUN', 'PROPN'] and \n",
    "            not token.is_stop and \n",
    "            len(token.text) > 2 and\n",
    "            token.text.isalpha()):\n",
    "            skills.append(token.lemma_.lower())\n",
    "    \n",
    "    return list(set(skills))\n",
    "\n",
    "def lemmatize_text(text, nlp_model):\n",
    "    \"\"\"\n",
    "    Lemmatize text and remove stopwords for improved matching.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        nlp_model: spaCy language model\n",
    "    \n",
    "    Returns:\n",
    "        Lemmatized text string\n",
    "    \"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n",
    "\n",
    "def find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes, top_n=5):\n",
    "    \"\"\"\n",
    "    Find top matching resumes for a job using TF-IDF cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of the job in the TF-IDF matrix\n",
    "        resume_tfidf: TF-IDF matrix for resumes\n",
    "        job_tfidf: TF-IDF matrix for jobs\n",
    "        df_resumes: DataFrame of resumes\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked matches and similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        job_vector = job_tfidf[job_index]\n",
    "        similarities = cosine_similarity(job_vector, resume_tfidf).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': df_resumes.iloc[idx]['ID'],\n",
    "                'Category': df_resumes.iloc[idx]['Category'],\n",
    "                'Similarity_Score': similarities[idx],\n",
    "                'Resume_Text': df_resumes.iloc[idx]['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF matching error: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache: 822 jobs, 2484 resumes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocess job postings and resumes with caching for performance.\n",
    "Combines job fields, cleans text, extracts skills, and lemmatizes for matching.\n",
    "\"\"\"\n",
    "if CACHE_JOBS.exists() and CACHE_RESUMES.exists():\n",
    "    try:\n",
    "        df_jobs_clean = pd.read_pickle(CACHE_JOBS)\n",
    "        df_resumes_clean = pd.read_pickle(CACHE_RESUMES)\n",
    "        print(f\"Loaded from cache: {len(df_jobs_clean)} jobs, {len(df_resumes_clean)} resumes\")\n",
    "        cache_available = True\n",
    "    except Exception as e:\n",
    "        print(f\"Cache load error: {e}. Reprocessing data...\")\n",
    "        cache_available = False\n",
    "    else:\n",
    "        cache_available = True\n",
    "else:\n",
    "    cache_available = False\n",
    "\n",
    "if not cache_available and df_jobs is not None and df_resumes is not None:\n",
    "    df_jobs_subset = df_jobs.head(1000)\n",
    "    df_resumes_subset = df_resumes.head(5000)\n",
    "    \n",
    "    print(f\"Processing: {len(df_jobs_subset)} jobs, {len(df_resumes_subset)} resumes\")\n",
    "    \n",
    "    job_columns = ['Title', 'Company', 'Location', 'JobDescription', 'JobRequirment', 'RequiredQual']\n",
    "    df_jobs_clean = df_jobs_subset[job_columns].copy()\n",
    "    df_jobs_clean = df_jobs_clean.dropna(subset=['Title', 'JobDescription'])\n",
    "    df_jobs_clean = df_jobs_clean.reset_index(drop=True)\n",
    "    \n",
    "    df_jobs_clean['CombinedText'] = (\n",
    "        df_jobs_clean['Title'].fillna('') + ' ' +\n",
    "        df_jobs_clean['JobDescription'].fillna('') + ' ' +\n",
    "        df_jobs_clean['JobRequirment'].fillna('') + ' ' +\n",
    "        df_jobs_clean['RequiredQual'].fillna('')\n",
    "    )\n",
    "    \n",
    "    df_jobs_clean['CleanText'] = df_jobs_clean['CombinedText'].apply(clean_text)\n",
    "    \n",
    "    if nlp:\n",
    "        df_jobs_clean['Skills'] = df_jobs_clean['CleanText'].apply(lambda x: extract_skills(x, nlp))\n",
    "        df_jobs_clean['LemmatizedText'] = df_jobs_clean['CleanText'].apply(lambda x: lemmatize_text(x, nlp))\n",
    "    else:\n",
    "        df_jobs_clean['Skills'] = [[] for _ in range(len(df_jobs_clean))]\n",
    "        df_jobs_clean['LemmatizedText'] = df_jobs_clean['CleanText']\n",
    "    \n",
    "    df_resumes_clean = df_resumes_subset.copy()\n",
    "    df_resumes_clean['CleanText'] = df_resumes_clean['Resume_str'].apply(clean_text)\n",
    "    \n",
    "    if nlp:\n",
    "        df_resumes_clean['Skills'] = df_resumes_clean['CleanText'].apply(lambda x: extract_skills(x, nlp))\n",
    "        df_resumes_clean['LemmatizedText'] = df_resumes_clean['CleanText'].apply(lambda x: lemmatize_text(x, nlp))\n",
    "    else:\n",
    "        df_resumes_clean['Skills'] = [[] for _ in range(len(df_resumes_clean))]\n",
    "        df_resumes_clean['LemmatizedText'] = df_resumes_clean['CleanText']\n",
    "    \n",
    "    df_jobs_clean.to_pickle(CACHE_JOBS)\n",
    "    df_resumes_clean.to_pickle(CACHE_RESUMES)\n",
    "    print(f\"Saved to cache: {len(df_jobs_clean)} jobs, {len(df_resumes_clean)} resumes\")\n",
    "elif df_jobs is None or df_resumes is None:\n",
    "    print(\"No data available for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix created: (3306, 5000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create TF-IDF vector representations for jobs and resumes.\n",
    "Combines all text to build a shared vocabulary for consistent feature space.\n",
    "\"\"\"\n",
    "if 'df_jobs_clean' in locals() and 'df_resumes_clean' in locals():\n",
    "    all_texts = list(df_jobs_clean['LemmatizedText']) + list(df_resumes_clean['LemmatizedText'])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.8\n",
    "    )\n",
    "    \n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    n_jobs = len(df_jobs_clean)\n",
    "    job_tfidf = tfidf_matrix[:n_jobs]\n",
    "    resume_tfidf = tfidf_matrix[n_jobs:]\n",
    "    \n",
    "    print(f\"TF-IDF matrix created: {tfidf_matrix.shape}\")\n",
    "else:\n",
    "    print(\"Cleaned data not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing methods for job: Chief Financial Officer\n",
      "================================================================================\n",
      "\n",
      "RESULTS COMPARISON:\n",
      "================================================================================\n",
      "\n",
      "TF-IDF Results:\n",
      " Rank  Resume_ID Category  Similarity_Score\n",
      "    1   12071138  FINANCE          0.438454\n",
      "    2   19234823 ADVOCATE          0.431891\n",
      "    3   18636651  FINANCE          0.426520\n",
      "    4   17392859  FINANCE          0.401932\n",
      "    5   84356308  FINANCE          0.398916\n",
      "\n",
      "BERT Results:\n",
      " Rank  Resume_ID Category  BERT_Similarity_Score\n",
      "    1   17392859  FINANCE               0.752344\n",
      "    2   15891494  FINANCE               0.743289\n",
      "    3   14722634  FINANCE               0.737250\n",
      "    4   26767199  FINANCE               0.730880\n",
      "    5   38441665  FINANCE               0.723948\n",
      "\n",
      "RoBERTa Results:\n",
      " Rank  Resume_ID    Category  RoBERTa_Similarity_Score\n",
      "    1   16507693 AGRICULTURE                  0.842645\n",
      "    2   19243556     FINANCE                  0.820709\n",
      "    3   19234823    ADVOCATE                  0.816237\n",
      "    4   38441665     FINANCE                  0.808682\n",
      "    5   26767199     FINANCE                  0.803197\n",
      "\n",
      "Enhanced BERT Results:\n",
      " Rank  Resume_ID Category  BERT_Similarity_Score  Skill_Overlap_Score  Combined_Score\n",
      "    1   14722634  FINANCE               0.737250             0.423611        0.643159\n",
      "    2   19234823 ADVOCATE               0.721044             0.451389        0.640147\n",
      "    3   17392859  FINANCE               0.752344             0.368056        0.637057\n",
      "    4   15891494  FINANCE               0.743289             0.381944        0.634886\n",
      "    5   81677620  FINANCE               0.715356             0.395833        0.619499\n",
      "\n",
      "Enhanced RoBERTa Results:\n",
      " Rank  Resume_ID    Category  RoBERTa_Similarity_Score  Skill_Overlap_Score  Combined_Score\n",
      "    1   16507693 AGRICULTURE                  0.842645             0.416667        0.714851\n",
      "    2   19234823    ADVOCATE                  0.816237             0.451389        0.706783\n",
      "    3   27409087     FINANCE                  0.802374             0.437500        0.692912\n",
      "    4   14722634     FINANCE                  0.801470             0.423611        0.688112\n",
      "    5   26975573  ACCOUNTANT                  0.781612             0.451389        0.682545\n",
      "Sample Job: Chief Financial Officer\n",
      "\n",
      "spaCy Skills (144): ['return', 'covenant', 'leadership', 'work', 'individual', 'projection', 'employee', 'word', 'concentration', 'principle']\n",
      "\n",
      "BERT Skills (0): []\n",
      "\n",
      "Skill Extraction Comparison:\n",
      "  spaCy skills: 144\n",
      "  BERT skills: 0\n",
      "  Overlap: 0\n",
      "  Jaccard similarity: 0.000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compare TF-IDF, BERT, and RoBERTa matching methods for performance evaluation.\n",
    "\"\"\"\n",
    "def compare_matching_methods(job_index=0, top_n=5):\n",
    "    \"\"\"\n",
    "    Compare TF-IDF, BERT, and RoBERTa matching methods on a sample job.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job to test\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing results from all methods\n",
    "    \"\"\"\n",
    "    if df_jobs is None or df_resumes is None:\n",
    "        print(\"Datasets not loaded. Run data loading cell first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Comparing methods for job: {df_jobs.iloc[job_index]['Title']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        tfidf_matches = find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes_clean, top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF method failed: {str(e)}\")\n",
    "        tfidf_matches = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        bert_matches = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT method failed: {str(e)}\")\n",
    "        bert_matches = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        roberta_matches = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa method failed: {str(e)}\")\n",
    "        roberta_matches = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        enhanced_bert_matches = enhanced_matching_bert(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced BERT method failed: {str(e)}\")\n",
    "        enhanced_bert_matches = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        enhanced_roberta_matches = enhanced_matching_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced RoBERTa method failed: {str(e)}\")\n",
    "        enhanced_roberta_matches = pd.DataFrame()\n",
    "    \n",
    "    print(\"\\nRESULTS COMPARISON:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not tfidf_matches.empty:\n",
    "        print(\"\\nTF-IDF Results:\")\n",
    "        print(tfidf_matches[['Rank', 'Resume_ID', 'Category', 'Similarity_Score']].to_string(index=False))\n",
    "    \n",
    "    if not bert_matches.empty:\n",
    "        print(\"\\nBERT Results:\")\n",
    "        print(bert_matches[['Rank', 'Resume_ID', 'Category', 'BERT_Similarity_Score']].to_string(index=False))\n",
    "    \n",
    "    if not roberta_matches.empty:\n",
    "        print(\"\\nRoBERTa Results:\")\n",
    "        print(roberta_matches[['Rank', 'Resume_ID', 'Category', 'RoBERTa_Similarity_Score']].to_string(index=False))\n",
    "    \n",
    "    if not enhanced_bert_matches.empty:\n",
    "        print(\"\\nEnhanced BERT Results:\")\n",
    "        print(enhanced_bert_matches[['Rank', 'Resume_ID', 'Category', 'BERT_Similarity_Score', 'Skill_Overlap_Score', 'Combined_Score']].to_string(index=False))\n",
    "    \n",
    "    if not enhanced_roberta_matches.empty:\n",
    "        print(\"\\nEnhanced RoBERTa Results:\")\n",
    "        print(enhanced_roberta_matches[['Rank', 'Resume_ID', 'Category', 'RoBERTa_Similarity_Score', 'Skill_Overlap_Score', 'Combined_Score']].to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'tfidf_matches': tfidf_matches,\n",
    "        'bert_matches': bert_matches,\n",
    "        'roberta_matches': roberta_matches,\n",
    "        'enhanced_bert_matches': enhanced_bert_matches,\n",
    "        'enhanced_roberta_matches': enhanced_roberta_matches\n",
    "    }\n",
    "\n",
    "def test_skill_extraction_comparison():\n",
    "    \"\"\"\n",
    "    Compare skill extraction methods between spaCy and BERT.\n",
    "    \"\"\"\n",
    "    if df_jobs is None or not BERT_AVAILABLE:\n",
    "        print(\"Datasets not loaded or BERT not available.\")\n",
    "        return\n",
    "    \n",
    "    if 'df_jobs_clean' in globals() and len(globals()['df_jobs_clean']) > 0:\n",
    "        sample_job = df_jobs_clean.iloc[0]\n",
    "        job_text = sample_job['CleanText']\n",
    "        \n",
    "        print(f\"Sample Job: {sample_job['Title']}\")\n",
    "        \n",
    "        if nlp:\n",
    "            spacy_skills = extract_skills(job_text, nlp)\n",
    "            print(f\"\\nspaCy Skills ({len(spacy_skills)}): {spacy_skills[:10]}\")\n",
    "        \n",
    "        bert_skills = extract_skills_bert(job_text)\n",
    "        print(f\"\\nBERT Skills ({len(bert_skills)}): {bert_skills}\")\n",
    "        \n",
    "        if nlp and spacy_skills:\n",
    "            spacy_set = set(spacy_skills)\n",
    "            bert_set = set(bert_skills)\n",
    "            overlap = len(spacy_set.intersection(bert_set))\n",
    "            union = len(spacy_set.union(bert_set))\n",
    "            \n",
    "            print(f\"\\nSkill Extraction Comparison:\")\n",
    "            print(f\"  spaCy skills: {len(spacy_skills)}\")\n",
    "            print(f\"  BERT skills: {len(bert_skills)}\")\n",
    "            print(f\"  Overlap: {overlap}\")\n",
    "            print(f\"  Jaccard similarity: {overlap/union:.3f}\")\n",
    "\n",
    "comparison_results = compare_matching_methods(job_index=0, top_n=5)\n",
    "test_skill_extraction_comparison()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT similarity test: 0.494\n",
      "RoBERTa similarity test: 0.365\n",
      "Skills extracted: ['learning', 'machine', 'python']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "System validation tests for BERT, RoBERTa similarity and skill extraction.\n",
    "\"\"\"\n",
    "if BERT_AVAILABLE:\n",
    "    if 'bert_model' in globals() and bert_model is not None:\n",
    "        similarity = calculate_bert_similarity(\"python developer\", \"software engineer\")\n",
    "        print(f\"BERT similarity test: {similarity:.3f}\")\n",
    "    \n",
    "    if 'roberta_model' in globals() and roberta_model is not None:\n",
    "        similarity = calculate_roberta_similarity(\"python developer\", \"software engineer\")\n",
    "        print(f\"RoBERTa similarity test: {similarity:.3f}\")\n",
    "\n",
    "if nlp:\n",
    "    skills = extract_skills(\"I know Python and machine learning\", nlp)\n",
    "    print(f\"Skills extracted: {skills}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF: Found 3 matches\n",
      "Top TF-IDF match: 12071138\n",
      "BERT: Found 3 matches\n",
      "Top BERT match: 17392859\n",
      "RoBERTa: Found 3 matches\n",
      "Top RoBERTa match: 16507693\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple validation test for TF-IDF, BERT, and RoBERTa matching methods.\n",
    "\"\"\"\n",
    "def simple_test():\n",
    "    \"\"\"\n",
    "    Validate that all matching methods work correctly.\n",
    "    \"\"\"\n",
    "    if df_jobs is None or df_resumes is None:\n",
    "        print(\"Datasets not loaded\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        tfidf_results = find_best_matches(0, resume_tfidf, job_tfidf, df_resumes_clean, 3)\n",
    "        print(f\"TF-IDF: Found {len(tfidf_results)} matches\")\n",
    "        if not tfidf_results.empty:\n",
    "            print(f\"Top TF-IDF match: {tfidf_results.iloc[0]['Resume_ID']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF error: {e}\")\n",
    "    \n",
    "    try:\n",
    "        bert_results = find_best_matches_bert(0, df_jobs_clean, df_resumes_clean, 3)\n",
    "        print(f\"BERT: Found {len(bert_results)} matches\")\n",
    "        if not bert_results.empty:\n",
    "            print(f\"Top BERT match: {bert_results.iloc[0]['Resume_ID']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"BERT error: {e}\")\n",
    "    \n",
    "    try:\n",
    "        roberta_results = find_best_matches_roberta(0, df_jobs_clean, df_resumes_clean, 3)\n",
    "        print(f\"RoBERTa: Found {len(roberta_results)} matches\")\n",
    "        if not roberta_results.empty:\n",
    "            print(f\"Top RoBERTa match: {roberta_results.iloc[0]['Resume_ID']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa error: {e}\")\n",
    "\n",
    "simple_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_jobs: Not available\n",
      "df_resumes: Not available\n",
      "df_jobs_clean: Not available\n",
      "df_resumes_clean: Not available\n",
      "job_tfidf: Not available\n",
      "resume_tfidf: Not available\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check availability of datasets and processed data structures.\n",
    "\"\"\"\n",
    "def check_data_availability():\n",
    "    \"\"\"\n",
    "    Display status of all required data structures.\n",
    "    \"\"\"\n",
    "    status = {\n",
    "        'df_jobs': 'df_jobs' in locals() and df_jobs is not None,\n",
    "        'df_resumes': 'df_resumes' in locals() and df_resumes is not None,\n",
    "        'df_jobs_clean': 'df_jobs_clean' in locals(),\n",
    "        'df_resumes_clean': 'df_resumes_clean' in locals(),\n",
    "        'job_tfidf': 'job_tfidf' in locals(),\n",
    "        'resume_tfidf': 'resume_tfidf' in locals()\n",
    "    }\n",
    "    \n",
    "    for key, value in status.items():\n",
    "        print(f\"{key}: {'Available' if value else 'Not available'}\")\n",
    "    \n",
    "    if status['df_jobs']:\n",
    "        print(f\"\\nOriginal data - Jobs: {df_jobs.shape}, Resumes: {df_resumes.shape if status['df_resumes'] else 'N/A'}\")\n",
    "    \n",
    "    if status['df_jobs_clean']:\n",
    "        print(f\"Cleaned data - Jobs: {df_jobs_clean.shape}, Resumes: {df_resumes_clean.shape if status['df_resumes_clean'] else 'N/A'}\")\n",
    "\n",
    "check_data_availability()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "\n",
      "BERT Semantic Similarity Demo:\n",
      "----------------------------------------\n",
      "'machine learning engineer'  'data scientist': 0.608\n",
      "'python developer'  'software engineer': 0.494\n",
      "'project manager'  'team lead': 0.309\n",
      "'marketing specialist'  'sales representative': 0.598\n",
      "\n",
      "RoBERTa Semantic Similarity Demo:\n",
      "----------------------------------------\n",
      "'machine learning engineer'  'data scientist': 0.597\n",
      "'python developer'  'software engineer': 0.365\n",
      "'project manager'  'team lead': 0.184\n",
      "'marketing specialist'  'sales representative': 0.384\n",
      "\n",
      "SYSTEM STATUS\n",
      "==================================================\n",
      "Datasets loaded: True\n",
      "BERT available: True\n",
      "spaCy available: True\n",
      "Flask available: True\n",
      "Database available: False\n",
      "\n",
      "Dataset Statistics:\n",
      "  Job posts: 19,001\n",
      "  Resumes: 2,484\n",
      "  Resume categories: 24\n",
      "\n",
      "Matching Methods Available:\n",
      "  TF-IDF + Cosine Similarity: Available\n",
      "  BERT Semantic Matching: Available\n",
      "  RoBERTa Semantic Matching: Available\n",
      "  Enhanced BERT + Skills: Available\n",
      "  Enhanced RoBERTa + Skills: Available\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BERT integration demonstration and system status overview.\n",
    "\"\"\"\n",
    "def demo_bert_features():\n",
    "    \"\"\"\n",
    "    Demonstrate BERT and RoBERTa semantic similarity capabilities.\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE:\n",
    "        print(\"BERT/RoBERTa is not available. Install transformers and torch.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Device: {device if 'device' in globals() else 'CPU'}\")\n",
    "    \n",
    "    test_pairs = [\n",
    "        (\"machine learning engineer\", \"data scientist\"),\n",
    "        (\"python developer\", \"software engineer\"),\n",
    "        (\"project manager\", \"team lead\"),\n",
    "        (\"marketing specialist\", \"sales representative\")\n",
    "    ]\n",
    "    \n",
    "    if 'bert_model' in globals() and bert_model is not None:\n",
    "        print(\"\\nBERT Semantic Similarity Demo:\")\n",
    "        print(\"-\" * 40)\n",
    "        for text1, text2 in test_pairs:\n",
    "            similarity = calculate_bert_similarity(text1, text2)\n",
    "            print(f\"'{text1}'  '{text2}': {similarity:.3f}\")\n",
    "    \n",
    "    if 'roberta_model' in globals() and roberta_model is not None:\n",
    "        print(\"\\nRoBERTa Semantic Similarity Demo:\")\n",
    "        print(\"-\" * 40)\n",
    "        for text1, text2 in test_pairs:\n",
    "            similarity = calculate_roberta_similarity(text1, text2)\n",
    "            print(f\"'{text1}'  '{text2}': {similarity:.3f}\")\n",
    "\n",
    "def system_status():\n",
    "    \"\"\"\n",
    "    Display current system status and available capabilities.\n",
    "    \"\"\"\n",
    "    print(\"\\nSYSTEM STATUS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"Datasets loaded: {df_jobs is not None and df_resumes is not None}\")\n",
    "    print(f\"BERT available: {BERT_AVAILABLE}\")\n",
    "    print(f\"spaCy available: {nlp is not None}\")\n",
    "    print(f\"Flask available: {FLASK_AVAILABLE}\")\n",
    "    print(f\"Database available: {DATABASE_AVAILABLE}\")\n",
    "    \n",
    "    if df_jobs is not None and df_resumes is not None:\n",
    "        print(f\"\\nDataset Statistics:\")\n",
    "        print(f\"  Job posts: {len(df_jobs):,}\")\n",
    "        print(f\"  Resumes: {len(df_resumes):,}\")\n",
    "        print(f\"  Resume categories: {df_resumes['Category'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nMatching Methods Available:\")\n",
    "    print(f\"  TF-IDF + Cosine Similarity: Available\")\n",
    "    print(f\"  BERT Semantic Matching: {'Available' if BERT_AVAILABLE and 'bert_model' in globals() and globals().get('bert_model') is not None else 'Not available'}\")\n",
    "    print(f\"  RoBERTa Semantic Matching: {'Available' if BERT_AVAILABLE and 'roberta_model' in globals() and globals().get('roberta_model') is not None else 'Not available'}\")\n",
    "    print(f\"  Enhanced BERT + Skills: {'Available' if BERT_AVAILABLE and 'bert_model' in globals() and globals().get('bert_model') is not None else 'Not available'}\")\n",
    "    print(f\"  Enhanced RoBERTa + Skills: {'Available' if BERT_AVAILABLE and 'roberta_model' in globals() and globals().get('roberta_model') is not None else 'Not available'}\")\n",
    "\n",
    "demo_bert_features()\n",
    "system_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate cell - functions already defined in cell 10\n",
    "# This cell can be removed or kept as reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job search results for 'software developer python':\n",
      "   Rank                                          Title  \\\n",
      "0     1                  Software Developer/Programmer   \n",
      "1     2                             Software developer   \n",
      "2     3  Senior Software Developer (several positions)   \n",
      "3     4                             Software Developer   \n",
      "4     5                         Developers Team Leader   \n",
      "\n",
      "                                       Company          Location  \\\n",
      "0                                      IIG LLC  Yerevan, Armenia   \n",
      "1                                     Xalt LLC  Yerevan, Armenia   \n",
      "2                                    ZenteX.AM  Yerevan, Armenia   \n",
      "3  Synergy International Systems, Inc./Armenia  Yerevan, Armenia   \n",
      "4                                    Zenteq.am  Yerevan, Armenia   \n",
      "\n",
      "   Similarity_Score  \\\n",
      "0          0.436298   \n",
      "1          0.419878   \n",
      "2          0.412981   \n",
      "3          0.345645   \n",
      "4          0.313760   \n",
      "\n",
      "                                                                                           Description  \n",
      "0                                                Development of programs for business applications....  \n",
      "1  Xalt LLC is seeking for a motivated and experienced\\r\\nSoftware Developer in Web environment who...  \n",
      "2  ZenteX.AM is seeking software developers to fill\\r\\npositions in its expanding development team....  \n",
      "3  Synergy International Systems, Inc./Armenia seeks to\\r\\nfill the long-term position of Software ...  \n",
      "4  The duties of the Developers Team Leader include\\r\\nplanning and permanent coordination of devel...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF based job search by keywords.\n",
    "\"\"\"\n",
    "def search_jobs_by_keywords(keywords, df_jobs, job_tfidf, vectorizer, top_n=5):\n",
    "    \"\"\"\n",
    "    Search for jobs matching keyword query using TF-IDF similarity.\n",
    "    \n",
    "    Args:\n",
    "        keywords: Search query string\n",
    "        df_jobs: DataFrame of job postings\n",
    "        job_tfidf: TF-IDF matrix for jobs\n",
    "        vectorizer: Fitted TfidfVectorizer instance\n",
    "        top_n: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches\n",
    "    \"\"\"\n",
    "    clean_keywords = clean_text(keywords)\n",
    "    keyword_vector = vectorizer.transform([clean_keywords])\n",
    "    similarities = cosine_similarity(keyword_vector, job_tfidf).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        job = df_jobs.iloc[idx]\n",
    "        results.append({\n",
    "            'Rank': i + 1,\n",
    "            'Title': job['Title'],\n",
    "            'Company': job['Company'],\n",
    "            'Location': job['Location'],\n",
    "            'Similarity_Score': similarities[idx],\n",
    "            'Description': job['JobDescription'][:200] + '...' if pd.notna(job['JobDescription']) else 'N/A'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "search_results = search_jobs_by_keywords(\"software developer python\", df_jobs_clean, job_tfidf, vectorizer)\n",
    "print(\"Job search results for 'software developer python':\")\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported files:\n",
      "  - cleaned_job_posts.csv\n",
      "  - cleaned_resumes.csv\n",
      "  - job_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export processed datasets and results to CSV files.\n",
    "\"\"\"\n",
    "df_jobs_clean.to_csv('cleaned_job_posts.csv', index=False)\n",
    "df_resumes_clean.to_csv('cleaned_resumes.csv', index=False)\n",
    "\n",
    "if 'enhanced_matches' in locals():\n",
    "    enhanced_matches.to_csv('job_resume_matches.csv', index=False)\n",
    "\n",
    "if 'search_results' in locals():\n",
    "    search_results.to_csv('job_search_results.csv', index=False)\n",
    "\n",
    "print(\"Exported files:\")\n",
    "print(\"  - cleaned_job_posts.csv\")\n",
    "print(\"  - cleaned_resumes.csv\")\n",
    "if 'enhanced_matches' in locals():\n",
    "    print(\"  - job_resume_matches.csv\")\n",
    "if 'search_results' in locals():\n",
    "    print(\"  - job_search_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI RECRUITMENT SYSTEM SUMMARY\n",
      "==================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "  Total Job Posts: 822\n",
      "  Total Resumes: 2484\n",
      "  Resume Categories: 24\n",
      "  Unique Companies: 416\n",
      "\n",
      "System Features:\n",
      "  - Job posting analysis and cleaning\n",
      "  - Resume parsing and skill extraction\n",
      "  - TF-IDF based text similarity matching\n",
      "  - BERT semantic matching\n",
      "  - Enhanced matching with skill overlap\n",
      "  - Interactive job search by keywords\n",
      "  - Results export to CSV\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "System summary and statistics.\n",
    "\"\"\"\n",
    "print(\"AI RECRUITMENT SYSTEM SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Total Job Posts: {len(df_jobs_clean)}\")\n",
    "print(f\"  Total Resumes: {len(df_resumes_clean)}\")\n",
    "print(f\"  Resume Categories: {df_resumes_clean['Category'].nunique()}\")\n",
    "print(f\"  Unique Companies: {df_jobs_clean['Company'].nunique()}\")\n",
    "\n",
    "print(f\"\\nSystem Features:\")\n",
    "print(\"  - Job posting analysis and cleaning\")\n",
    "print(\"  - Resume parsing and skill extraction\")\n",
    "print(\"  - TF-IDF based text similarity matching\")\n",
    "print(\"  - BERT semantic matching\")\n",
    "print(\"  - Enhanced matching with skill overlap\")\n",
    "print(\"  - Interactive job search by keywords\")\n",
    "print(\"  - Results export to CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [0]  Chief Financial Officer | AMERIA Investment Consulting Company | Yerevan, Armenia\n",
      "\n",
      "Top 10 candidates (RoBERTa):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Resume_ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>Resume_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16507693</td>\n",
       "      <td>AGRICULTURE</td>\n",
       "      <td>0.842645</td>\n",
       "      <td>BUDGET ANALYST SERIES 0560       Summary      Accounting Skills    Knowledge of automa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19243556</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.820709</td>\n",
       "      <td>DIRECTOR OF FINANCE       Executive Profile     Dynamic, results-oriented Controller wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19234823</td>\n",
       "      <td>ADVOCATE</td>\n",
       "      <td>0.816237</td>\n",
       "      <td>FINANCE DIRECTOR       Professional Summary    To find a new and challenging position t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>38441665</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.808682</td>\n",
       "      <td>FINANCE DIRECTOR           Professional Summary     Results oriented, dependable and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26767199</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.803197</td>\n",
       "      <td>FINANCE MANAGER         Summary     Flexible Financial Manager with the ability to mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>27409087</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.802374</td>\n",
       "      <td>HEAD OF ACCOUNTS AND FINANCE           Summary     Flexible Accountant who adapts seaml...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>12802330</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>0.802321</td>\n",
       "      <td>LEAD ACCOUNTANT             Highlights          QuickBooks, Peachtree, In-house Account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>14722634</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.801470</td>\n",
       "      <td>FINANCE DIRECTOR       Summary    Remarkably astute and analytical professional with ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>23139819</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>0.792290</td>\n",
       "      <td>ACCOUNTANT       Summary    \\n\\nAccomplished professional with exceptional skills\\ndeve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20918464</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.791255</td>\n",
       "      <td>SENIOR ACCOUNTANT / FINANCE CONTROLLER       Summary                    Aim to work for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Resume_ID     Category     Score  \\\n",
       "0     1   16507693  AGRICULTURE  0.842645   \n",
       "1     2   19243556      FINANCE  0.820709   \n",
       "2     3   19234823     ADVOCATE  0.816237   \n",
       "3     4   38441665      FINANCE  0.808682   \n",
       "4     5   26767199      FINANCE  0.803197   \n",
       "5     6   27409087      FINANCE  0.802374   \n",
       "6     7   12802330   ACCOUNTANT  0.802321   \n",
       "7     8   14722634      FINANCE  0.801470   \n",
       "8     9   23139819   ACCOUNTANT  0.792290   \n",
       "9    10   20918464      FINANCE  0.791255   \n",
       "\n",
       "                                                                                           Resume_Text  \n",
       "0           BUDGET ANALYST SERIES 0560       Summary      Accounting Skills    Knowledge of automa...  \n",
       "1           DIRECTOR OF FINANCE       Executive Profile     Dynamic, results-oriented Controller wi...  \n",
       "2           FINANCE DIRECTOR       Professional Summary    To find a new and challenging position t...  \n",
       "3           FINANCE DIRECTOR           Professional Summary     Results oriented, dependable and mo...  \n",
       "4           FINANCE MANAGER         Summary     Flexible Financial Manager with the ability to mult...  \n",
       "5           HEAD OF ACCOUNTS AND FINANCE           Summary     Flexible Accountant who adapts seaml...  \n",
       "6           LEAD ACCOUNTANT             Highlights          QuickBooks, Peachtree, In-house Account...  \n",
       "7           FINANCE DIRECTOR       Summary    Remarkably astute and analytical professional with ov...  \n",
       "8           ACCOUNTANT       Summary    \\n\\nAccomplished professional with exceptional skills\\ndeve...  \n",
       "9           SENIOR ACCOUNTANT / FINANCE CONTROLLER       Summary                    Aim to work for...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Find top candidates for a job posting using BERT (preferred) or TF-IDF matching.\n",
    "\"\"\"\n",
    "def top_candidates_for_job(job_index=None, title_contains=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Find top matching candidates for a job by index or title search.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job in df_jobs_clean (optional)\n",
    "        title_contains: Substring to search in job titles (optional)\n",
    "        top_n: Number of top candidates to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked candidates\n",
    "    \"\"\"\n",
    "    required = ['df_jobs_clean', 'df_resumes_clean']\n",
    "    for v in required:\n",
    "        if v not in globals():\n",
    "            raise RuntimeError(f\"{v} not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    if job_index is None and not title_contains:\n",
    "        raise ValueError(\"Provide either job_index or title_contains.\")\n",
    "\n",
    "    if job_index is None:\n",
    "        mask = df_jobs_clean['Title'].fillna('').str.contains(title_contains, case=False, na=False)\n",
    "        if not mask.any():\n",
    "            raise ValueError(f\"No job found with title containing: {title_contains}\")\n",
    "        job_index = mask.idxmax()\n",
    "\n",
    "    job_row = df_jobs_clean.iloc[job_index]\n",
    "    print(f\"Job [{job_index}]  {job_row['Title']} | {job_row.get('Company','N/A')} | {job_row.get('Location','N/A')}\")\n",
    "\n",
    "    use_roberta = 'find_best_matches_roberta' in globals() and BERT_AVAILABLE and (roberta_model is not None)\n",
    "    use_bert = 'find_best_matches_bert' in globals() and BERT_AVAILABLE and (bert_model is not None)\n",
    "    results = None\n",
    "\n",
    "    if use_roberta:\n",
    "        try:\n",
    "            results = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "            results = results[['Rank','Resume_ID','Category','RoBERTa_Similarity_Score','Resume_Text']]\n",
    "            results = results.rename(columns={'RoBERTa_Similarity_Score':'Score'})\n",
    "            method = \"RoBERTa\"\n",
    "        except Exception as e:\n",
    "            print(f\"RoBERTa matching unavailable: {e}\")\n",
    "            results = None\n",
    "\n",
    "    if results is None and use_bert:\n",
    "        try:\n",
    "            results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "            results = results[['Rank','Resume_ID','Category','BERT_Similarity_Score','Resume_Text']]\n",
    "            results = results.rename(columns={'BERT_Similarity_Score':'Score'})\n",
    "            method = \"BERT\"\n",
    "        except Exception as e:\n",
    "            print(f\"BERT matching unavailable: {e}\")\n",
    "            results = None\n",
    "\n",
    "    if results is None:\n",
    "        required_tfidf = ['job_tfidf','resume_tfidf','find_best_matches']\n",
    "        if not all(r in globals() for r in required_tfidf):\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run TF-IDF vectorization cell first.\")\n",
    "        results = find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes_clean, top_n=top_n)\n",
    "        results = results[['Rank','Resume_ID','Category','Similarity_Score','Resume_Text']]\n",
    "        results = results.rename(columns={'Similarity_Score':'Score'})\n",
    "        method = \"TF-IDF\"\n",
    "\n",
    "    print(f\"\\nTop {top_n} candidates ({method}):\")\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "top10 = top_candidates_for_job(job_index=0, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find best matching jobs for a candidate resume using BERT (preferred) or TF-IDF matching.\n",
    "\"\"\"\n",
    "def find_best_jobs_for_resume(resume_index, df_jobs, df_resumes, job_tfidf, resume_tfidf, top_n=10):\n",
    "    \"\"\"\n",
    "    Find top matching jobs for a resume using TF-IDF cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of the resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        job_tfidf: TF-IDF matrix for jobs\n",
    "        resume_tfidf: TF-IDF matrix for resumes\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches and similarity scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resume_vector = resume_tfidf[resume_index]\n",
    "        similarities = cosine_similarity(resume_vector, job_tfidf).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job.get('Company', 'N/A'),\n",
    "                'Location': job.get('Location', 'N/A'),\n",
    "                'Similarity_Score': similarities[idx],\n",
    "                'Description': job.get('JobDescription', 'N/A')[:200] + '...' if pd.notna(job.get('JobDescription', '')) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def find_best_jobs_for_resume_bert(resume_index, df_jobs, df_resumes, top_n=10):\n",
    "    \"\"\"\n",
    "    Find top matching jobs for a resume using BERT semantic embeddings.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of the resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings with 'CleanText' column\n",
    "        df_resumes: DataFrame of resumes with 'CleanText' column\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches and similarity scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        resume_text = df_resumes.iloc[resume_index]['CleanText']\n",
    "        job_texts = df_jobs['CleanText'].tolist()\n",
    "        \n",
    "        resume_embedding = bert_model.encode([resume_text])\n",
    "        job_embeddings = bert_model.encode(job_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(resume_embedding, job_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job.get('Company', 'N/A'),\n",
    "                'Location': job.get('Location', 'N/A'),\n",
    "                'BERT_Similarity_Score': similarities[idx],\n",
    "                'Description': job.get('JobDescription', 'N/A')[:200] + '...' if pd.notna(job.get('JobDescription', '')) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def find_best_jobs_for_resume_roberta(resume_index, df_jobs, df_resumes, top_n=10):\n",
    "    \"\"\"\n",
    "    Find top matching jobs for a resume using RoBERTa semantic embeddings.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of the resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings with 'CleanText' column\n",
    "        df_resumes: DataFrame of resumes with 'CleanText' column\n",
    "        top_n: Number of top matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches and similarity scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or roberta_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        resume_text = df_resumes.iloc[resume_index]['CleanText']\n",
    "        job_texts = df_jobs['CleanText'].tolist()\n",
    "        \n",
    "        resume_embedding = roberta_model.encode([resume_text])\n",
    "        job_embeddings = roberta_model.encode(job_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(resume_embedding, job_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job.get('Company', 'N/A'),\n",
    "                'Location': job.get('Location', 'N/A'),\n",
    "                'RoBERTa_Similarity_Score': similarities[idx],\n",
    "                'Description': job.get('JobDescription', 'N/A')[:200] + '...' if pd.notna(job.get('JobDescription', '')) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"RoBERTa matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def enhanced_jobs_for_resume_bert(resume_index, df_jobs, df_resumes, top_n=10, skill_weight=0.3, bert_weight=0.7):\n",
    "    \"\"\"\n",
    "    Enhanced matching combining BERT semantic similarity with skill overlap.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of the resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        top_n: Number of top matches to return\n",
    "        skill_weight: Weight for skill overlap score (default 0.3)\n",
    "        bert_weight: Weight for BERT similarity score (default 0.7)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches and combined scores\n",
    "    \"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        resume = df_resumes.iloc[resume_index]\n",
    "        resume_text = resume['CleanText']\n",
    "        resume_skills = set(resume['Skills']) if resume['Skills'] else set()\n",
    "        \n",
    "        resume_embedding = bert_model.encode([resume_text])\n",
    "        job_texts = df_jobs['CleanText'].tolist()\n",
    "        job_embeddings = bert_model.encode(job_texts)\n",
    "        \n",
    "        bert_similarities = cosine_similarity(resume_embedding, job_embeddings).flatten()\n",
    "        \n",
    "        skill_scores = []\n",
    "        for idx, job in df_jobs.iterrows():\n",
    "            job_skills = set(job['Skills']) if job['Skills'] else set()\n",
    "            \n",
    "            if resume_skills and job_skills:\n",
    "                overlap = len(resume_skills.intersection(job_skills))\n",
    "                skill_score = overlap / len(resume_skills) if resume_skills else 0\n",
    "            else:\n",
    "                skill_score = 0\n",
    "            \n",
    "            skill_scores.append(skill_score)\n",
    "        \n",
    "        combined_scores = bert_weight * bert_similarities + skill_weight * np.array(skill_scores)\n",
    "        top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job.get('Company', 'N/A'),\n",
    "                'Location': job.get('Location', 'N/A'),\n",
    "                'BERT_Similarity_Score': bert_similarities[idx],\n",
    "                'Skill_Overlap_Score': skill_scores[idx],\n",
    "                'Combined_Score': combined_scores[idx],\n",
    "                'Description': job.get('JobDescription', 'N/A')[:200] + '...' if pd.notna(job.get('JobDescription', '')) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def find_jobs_for_candidate(resume_index=None, resume_id=None, top_n=10):\n",
    "    \"\"\"\n",
    "    Find top matching jobs for a candidate by resume index or ID.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of resume in df_resumes_clean (optional)\n",
    "        resume_id: ID of the resume (optional)\n",
    "        top_n: Number of top job matches to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with ranked job matches\n",
    "    \"\"\"\n",
    "    # Access variables from global scope (Jupyter notebook)\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean not found. Please run the data preprocessing cell (Cell 11) first.\")\n",
    "    if 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_resumes_clean not found. Please run the data preprocessing cell (Cell 11) first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    if resume_index is None and resume_id is None:\n",
    "        raise ValueError(\"Provide either resume_index or resume_id.\")\n",
    "    \n",
    "    if resume_index is None:\n",
    "        mask = df_resumes_clean['ID'] == resume_id\n",
    "        if not mask.any():\n",
    "            raise ValueError(f\"No resume found with ID: {resume_id}\")\n",
    "        resume_index = mask.idxmax()\n",
    "    \n",
    "    resume_row = df_resumes_clean.iloc[resume_index]\n",
    "    print(f\"Resume [{resume_index}]  ID: {resume_row['ID']} | Category: {resume_row.get('Category','N/A')}\")\n",
    "    print(f\"Resume preview: {resume_row['Resume_str'][:150]}...\")\n",
    "    \n",
    "    use_roberta = ('find_best_jobs_for_resume_roberta' in g and \n",
    "                   'BERT_AVAILABLE' in g and g.get('BERT_AVAILABLE', False) and \n",
    "                   g.get('roberta_model') is not None)\n",
    "    use_bert = ('find_best_jobs_for_resume_bert' in g and \n",
    "                'BERT_AVAILABLE' in g and g.get('BERT_AVAILABLE', False) and \n",
    "                g.get('bert_model') is not None)\n",
    "    results = None\n",
    "    \n",
    "    if use_roberta:\n",
    "        try:\n",
    "            results = g['find_best_jobs_for_resume_roberta'](resume_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "            results = results[['Rank','Title','Company','Location','RoBERTa_Similarity_Score','Description']]\n",
    "            results = results.rename(columns={'RoBERTa_Similarity_Score':'Score'})\n",
    "            method = \"RoBERTa\"\n",
    "        except Exception as e:\n",
    "            print(f\"RoBERTa matching unavailable: {e}\")\n",
    "            results = None\n",
    "    \n",
    "    if results is None and use_bert:\n",
    "        try:\n",
    "            results = g['find_best_jobs_for_resume_bert'](resume_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "            results = results[['Rank','Title','Company','Location','BERT_Similarity_Score','Description']]\n",
    "            results = results.rename(columns={'BERT_Similarity_Score':'Score'})\n",
    "            method = \"BERT\"\n",
    "        except Exception as e:\n",
    "            print(f\"BERT matching unavailable: {e}\")\n",
    "            results = None\n",
    "    \n",
    "    if results is None:\n",
    "        if 'job_tfidf' not in g:\n",
    "            raise RuntimeError(\"job_tfidf not found. Please run the TF-IDF vectorization cell (Cell 12) first.\")\n",
    "        if 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"resume_tfidf not found. Please run the TF-IDF vectorization cell (Cell 12) first.\")\n",
    "        \n",
    "        results = g['find_best_jobs_for_resume'](resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                                 g['job_tfidf'], g['resume_tfidf'], top_n=top_n)\n",
    "        results = results[['Rank','Title','Company','Location','Similarity_Score','Description']]\n",
    "        results = results.rename(columns={'Similarity_Score':'Score'})\n",
    "        method = \"TF-IDF\"\n",
    "    \n",
    "    print(f\"\\nTop {top_n} matching jobs ({method}):\")\n",
    "    display(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Batch processing functions for multiple jobs/resumes matching.\n",
    "\"\"\"\n",
    "def batch_find_jobs_for_resume(resume_indices, df_jobs, df_resumes, job_tfidf, resume_tfidf, \n",
    "                                model_type='bert', top_n=10):\n",
    "    \"\"\"\n",
    "    Find top N jobs for multiple resumes (batch processing).\n",
    "    \n",
    "    Args:\n",
    "        resume_indices: List of resume indices or single index\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        job_tfidf: TF-IDF matrix for jobs\n",
    "        resume_tfidf: TF-IDF matrix for resumes\n",
    "        model_type: 'bert', 'roberta', or 'tfidf'\n",
    "        top_n: Number of top jobs to return per resume\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping resume_index to DataFrame of top jobs\n",
    "    \"\"\"\n",
    "    if isinstance(resume_indices, int):\n",
    "        resume_indices = [resume_indices]\n",
    "    \n",
    "    results = {}\n",
    "    g = globals()\n",
    "    \n",
    "    for resume_idx in resume_indices:\n",
    "        if model_type.lower() == 'bert':\n",
    "            if 'find_best_jobs_for_resume_bert' in g:\n",
    "                results[resume_idx] = find_best_jobs_for_resume_bert(\n",
    "                    resume_idx, df_jobs, df_resumes, top_n=top_n\n",
    "                )\n",
    "        elif model_type.lower() == 'roberta':\n",
    "            if 'find_best_jobs_for_resume_roberta' in g:\n",
    "                results[resume_idx] = find_best_jobs_for_resume_roberta(\n",
    "                    resume_idx, df_jobs, df_resumes, top_n=top_n\n",
    "                )\n",
    "        else:  # TF-IDF\n",
    "            results[resume_idx] = find_best_jobs_for_resume(\n",
    "                resume_idx, df_jobs, df_resumes, job_tfidf, resume_tfidf, top_n=top_n\n",
    "            )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def batch_find_resumes_for_job(job_indices, df_jobs, df_resumes, job_tfidf, resume_tfidf,\n",
    "                                model_type='bert', top_n=10):\n",
    "    \"\"\"\n",
    "    Find top N resumes for multiple jobs (batch processing).\n",
    "    \n",
    "    Args:\n",
    "        job_indices: List of job indices or single index\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        job_tfidf: TF-IDF matrix for jobs\n",
    "        resume_tfidf: TF-IDF matrix for resumes\n",
    "        model_type: 'bert', 'roberta', or 'tfidf'\n",
    "        top_n: Number of top resumes to return per job\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping job_index to DataFrame of top resumes\n",
    "    \"\"\"\n",
    "    if isinstance(job_indices, int):\n",
    "        job_indices = [job_indices]\n",
    "    \n",
    "    results = {}\n",
    "    g = globals()\n",
    "    \n",
    "    for job_idx in job_indices:\n",
    "        if model_type.lower() == 'bert':\n",
    "            if 'find_best_matches_bert' in g:\n",
    "                results[job_idx] = find_best_matches_bert(\n",
    "                    job_idx, df_jobs, df_resumes, top_n=top_n\n",
    "                )\n",
    "        elif model_type.lower() == 'roberta':\n",
    "            if 'find_best_matches_roberta' in g:\n",
    "                results[job_idx] = find_best_matches_roberta(\n",
    "                    job_idx, df_jobs, df_resumes, top_n=top_n\n",
    "                )\n",
    "        else:  # TF-IDF\n",
    "            results[job_idx] = find_best_matches(\n",
    "                job_idx, resume_tfidf, job_tfidf, df_resumes, top_n=top_n\n",
    "            )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_top_n_jobs_for_resume(resume_index, n=10, model='bert'):\n",
    "    \"\"\"\n",
    "    Get top N jobs for a single resume.\n",
    "    \n",
    "    Args:\n",
    "        resume_index: Index of resume in df_resumes_clean\n",
    "        n: Number of top jobs to return\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top N matching jobs\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    resume_row = df_resumes_clean.iloc[resume_index]\n",
    "    print(f\"Resume [{resume_index}]  ID: {resume_row['ID']} | Category: {resume_row.get('Category','N/A')}\")\n",
    "    \n",
    "    if model.lower() == 'bert' and 'find_best_jobs_for_resume_bert' in g:\n",
    "        results = find_best_jobs_for_resume_bert(resume_index, df_jobs_clean, df_resumes_clean, top_n=n)\n",
    "        results = results.rename(columns={'BERT_Similarity_Score': 'Score'})\n",
    "    elif model.lower() == 'roberta' and 'find_best_jobs_for_resume_roberta' in g:\n",
    "        results = find_best_jobs_for_resume_roberta(resume_index, df_jobs_clean, df_resumes_clean, top_n=n)\n",
    "        results = results.rename(columns={'RoBERTa_Similarity_Score': 'Score'})\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run TF-IDF vectorization cell first.\")\n",
    "        results = find_best_jobs_for_resume(resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                           g['job_tfidf'], g['resume_tfidf'], top_n=n)\n",
    "        results = results.rename(columns={'Similarity_Score': 'Score'})\n",
    "    \n",
    "    print(f\"\\nTop {n} matching jobs ({model.upper()}):\")\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "def get_top_n_resumes_for_job(job_index, n=10, model='bert'):\n",
    "    \"\"\"\n",
    "    Get top N resumes for a single job.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job in df_jobs_clean\n",
    "        n: Number of top resumes to return\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top N matching resumes\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    job_row = df_jobs_clean.iloc[job_index]\n",
    "    print(f\"Job [{job_index}]  {job_row['Title']} | {job_row.get('Company','N/A')}\")\n",
    "    \n",
    "    if model.lower() == 'bert' and 'find_best_matches_bert' in g:\n",
    "        results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=n)\n",
    "        results = results.rename(columns={'BERT_Similarity_Score': 'Score'})\n",
    "    elif model.lower() == 'roberta' and 'find_best_matches_roberta' in g:\n",
    "        results = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=n)\n",
    "        results = results.rename(columns={'RoBERTa_Similarity_Score': 'Score'})\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run TF-IDF vectorization cell first.\")\n",
    "        results = find_best_matches(job_index, g['resume_tfidf'], g['job_tfidf'], df_resumes_clean, top_n=n)\n",
    "        results = results.rename(columns={'Similarity_Score': 'Score'})\n",
    "    \n",
    "    print(f\"\\nTop {n} matching resumes ({model.upper()}):\")\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# Get top 10 jobs for resume index 0 using BERT\n",
    "# jobs = get_top_n_jobs_for_resume(resume_index=0, n=10, model='bert')\n",
    "\n",
    "# Get top 10 resumes for job index 0 using RoBERTa\n",
    "# resumes = get_top_n_resumes_for_job(job_index=0, n=10, model='roberta')\n",
    "\n",
    "# Batch processing: Get top 5 jobs for multiple resumes\n",
    "# batch_results = batch_find_jobs_for_resume([0, 1, 2], df_jobs_clean, df_resumes_clean, \n",
    "#                                            job_tfidf, resume_tfidf, model_type='bert', top_n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Match Summary for hiring managers.\n",
    "Provides detailed analysis of candidate-job fit including skills match, gaps, and alignment level.\n",
    "\"\"\"\n",
    "def generate_match_summary(job_index, resume_index, df_jobs, df_resumes, \n",
    "                           similarity_score, model_type='bert', threshold=0.6):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive match summary for hiring managers.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job in df_jobs\n",
    "        resume_index: Index of resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        similarity_score: Calculated similarity score\n",
    "        model_type: Type of model used ('bert', 'roberta', 'tfidf')\n",
    "        threshold: Minimum score threshold for match (default 0.6)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing match summary components\n",
    "    \"\"\"\n",
    "    job = df_jobs.iloc[job_index]\n",
    "    resume = df_resumes.iloc[resume_index]\n",
    "    \n",
    "    job_skills = set(job.get('Skills', [])) if job.get('Skills') else set()\n",
    "    resume_skills = set(resume.get('Skills', [])) if resume.get('Skills') else set()\n",
    "    \n",
    "    # Calculate skill overlap\n",
    "    matching_skills = job_skills.intersection(resume_skills)\n",
    "    missing_skills = job_skills - resume_skills\n",
    "    extra_skills = resume_skills - job_skills\n",
    "    \n",
    "    skill_match_ratio = len(matching_skills) / len(job_skills) if job_skills else 0\n",
    "    \n",
    "    # Determine alignment level\n",
    "    if similarity_score >= 0.75 and skill_match_ratio >= 0.7:\n",
    "        alignment_level = \"Excellent Match\"\n",
    "        recommendation = \"Strongly Recommended\"\n",
    "    elif similarity_score >= 0.65 and skill_match_ratio >= 0.5:\n",
    "        alignment_level = \"Good Match\"\n",
    "        recommendation = \"Recommended\"\n",
    "    elif similarity_score >= threshold and skill_match_ratio >= 0.3:\n",
    "        alignment_level = \"Moderate Match\"\n",
    "        recommendation = \"Consider with Training\"\n",
    "    else:\n",
    "        alignment_level = \"Weak Match\"\n",
    "        recommendation = \"Not Recommended\"\n",
    "    \n",
    "    # Generate summary text\n",
    "    summary = {\n",
    "        'candidate_id': resume.get('ID', 'N/A'),\n",
    "        'candidate_category': resume.get('Category', 'N/A'),\n",
    "        'job_title': job.get('Title', 'N/A'),\n",
    "        'company': job.get('Company', 'N/A'),\n",
    "        'similarity_score': round(similarity_score, 3),\n",
    "        'alignment_level': alignment_level,\n",
    "        'recommendation': recommendation,\n",
    "        'why_fit': f\"Candidate demonstrates {similarity_score*100:.1f}% semantic alignment with the job requirements. \"\n",
    "                  f\"Skill overlap of {skill_match_ratio*100:.1f}% indicates relevant experience.\",\n",
    "        'matching_skills': list(matching_skills)[:10],\n",
    "        'missing_skills': list(missing_skills)[:10],\n",
    "        'extra_skills': list(extra_skills)[:10],\n",
    "        'skill_match_ratio': round(skill_match_ratio, 3),\n",
    "        'gaps': f\"Missing {len(missing_skills)} key skills: {', '.join(list(missing_skills)[:5])}\" if missing_skills else \"No significant skill gaps identified.\"\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "def format_match_summary(summary_dict):\n",
    "    \"\"\"\n",
    "    Format match summary as a readable report for hiring managers.\n",
    "    \n",
    "    Args:\n",
    "        summary_dict: Dictionary from generate_match_summary()\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string report\n",
    "    \"\"\"\n",
    "    report = f\"\"\"\n",
    "{'='*70}\n",
    "MATCH SUMMARY REPORT\n",
    "{'='*70}\n",
    "\n",
    "Job Position: {summary_dict['job_title']}\n",
    "Company: {summary_dict['company']}\n",
    "Candidate ID: {summary_dict['candidate_id']}\n",
    "Candidate Category: {summary_dict['candidate_category']}\n",
    "\n",
    "OVERALL ASSESSMENT\n",
    "{'-'*70}\n",
    "Similarity Score: {summary_dict['similarity_score']:.3f}\n",
    "Alignment Level: {summary_dict['alignment_level']}\n",
    "Recommendation: {summary_dict['recommendation']}\n",
    "\n",
    "WHY THIS CANDIDATE IS A FIT\n",
    "{'-'*70}\n",
    "{summary_dict['why_fit']}\n",
    "\n",
    "SKILLS ANALYSIS\n",
    "{'-'*70}\n",
    "Matching Skills ({len(summary_dict['matching_skills'])}): {', '.join(summary_dict['matching_skills'][:10])}\n",
    "Skill Match Ratio: {summary_dict['skill_match_ratio']*100:.1f}%\n",
    "\n",
    "GAPS IDENTIFIED\n",
    "{'-'*70}\n",
    "{summary_dict['gaps']}\n",
    "\n",
    "ADDITIONAL SKILLS\n",
    "{'-'*70}\n",
    "Candidate has {len(summary_dict['extra_skills'])} additional skills: {', '.join(summary_dict['extra_skills'][:5])}\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "def get_match_summary_for_candidate(job_index, resume_index, model='bert'):\n",
    "    \"\"\"\n",
    "    Get formatted match summary for a specific job-resume pair.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job\n",
    "        resume_index: Index of resume\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "    \n",
    "    Returns:\n",
    "        Formatted match summary string\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    if model.lower() == 'bert' and 'find_best_matches_bert' in g:\n",
    "        results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['BERT_Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    elif model.lower() == 'roberta' and 'find_best_matches_roberta' in g:\n",
    "        results = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['RoBERTa_Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run TF-IDF vectorization cell first.\")\n",
    "        results = find_best_matches(job_index, g['resume_tfidf'], g['job_tfidf'], df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    \n",
    "    summary = generate_match_summary(job_index, resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                     score, model_type=model)\n",
    "    return format_match_summary(summary)\n",
    "\n",
    "# Example usage:\n",
    "# summary = get_match_summary_for_candidate(job_index=0, resume_index=0, model='bert')\n",
    "# print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Feedback Report for rejected candidates.\n",
    "Provides actionable insights on missing skills, learning paths, and improvements.\n",
    "\"\"\"\n",
    "def generate_candidate_feedback(job_index, resume_index, df_jobs, df_resumes, \n",
    "                               similarity_score, model_type='bert', threshold=0.6):\n",
    "    \"\"\"\n",
    "    Generate detailed feedback report for candidates who don't meet the threshold.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job in df_jobs\n",
    "        resume_index: Index of resume in df_resumes\n",
    "        df_jobs: DataFrame of job postings\n",
    "        df_resumes: DataFrame of resumes\n",
    "        similarity_score: Calculated similarity score\n",
    "        model_type: Type of model used\n",
    "        threshold: Minimum score threshold (default 0.6)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing feedback components\n",
    "    \"\"\"\n",
    "    job = df_jobs.iloc[job_index]\n",
    "    resume = df_resumes.iloc[resume_index]\n",
    "    \n",
    "    job_skills = set(job.get('Skills', [])) if job.get('Skills') else set()\n",
    "    resume_skills = set(resume.get('Skills', [])) if resume.get('Skills') else set()\n",
    "    \n",
    "    missing_skills = job_skills - resume_skills\n",
    "    matching_skills = job_skills.intersection(resume_skills)\n",
    "    \n",
    "    skill_gap = len(missing_skills) / len(job_skills) if job_skills else 1.0\n",
    "    \n",
    "    # Determine improvement areas\n",
    "    improvement_areas = []\n",
    "    if similarity_score < threshold:\n",
    "        improvement_areas.append(\"Overall profile alignment needs improvement\")\n",
    "    if skill_gap > 0.3:\n",
    "        improvement_areas.append(f\"Missing {len(missing_skills)} critical skills\")\n",
    "    if len(matching_skills) < 3:\n",
    "        improvement_areas.append(\"Limited overlap with required skills\")\n",
    "    \n",
    "    # Generate learning path suggestions\n",
    "    learning_paths = []\n",
    "    skill_categories = {\n",
    "        'technical': ['python', 'java', 'javascript', 'sql', 'database', 'aws', 'docker'],\n",
    "        'soft_skills': ['leadership', 'communication', 'project management', 'agile', 'scrum'],\n",
    "        'domain': ['machine learning', 'data science', 'web development', 'mobile development']\n",
    "    }\n",
    "    \n",
    "    for skill in list(missing_skills)[:5]:\n",
    "        category = 'technical'\n",
    "        for cat, skills in skill_categories.items():\n",
    "            if any(s in skill.lower() for s in skills):\n",
    "                category = cat\n",
    "                break\n",
    "        \n",
    "        if category == 'technical':\n",
    "            learning_paths.append(f\"{skill}: Consider online courses (Coursera, Udemy) or certification programs\")\n",
    "        elif category == 'soft_skills':\n",
    "            learning_paths.append(f\"{skill}: Practice through projects, mentorship, or workshops\")\n",
    "        else:\n",
    "            learning_paths.append(f\"{skill}: Build portfolio projects and gain hands-on experience\")\n",
    "    \n",
    "    # Actionable improvements\n",
    "    improvements = []\n",
    "    if similarity_score < 0.5:\n",
    "        improvements.append(\"Enhance resume keywords to better match job description terminology\")\n",
    "    if len(matching_skills) < len(job_skills) * 0.5:\n",
    "        improvements.append(f\"Focus on acquiring top {min(5, len(missing_skills))} missing skills: {', '.join(list(missing_skills)[:5])}\")\n",
    "    improvements.append(\"Highlight relevant projects and experiences more prominently\")\n",
    "    improvements.append(\"Consider obtaining relevant certifications to strengthen profile\")\n",
    "    \n",
    "    feedback = {\n",
    "        'candidate_id': resume.get('ID', 'N/A'),\n",
    "        'job_title': job.get('Title', 'N/A'),\n",
    "        'company': job.get('Company', 'N/A'),\n",
    "        'current_score': round(similarity_score, 3),\n",
    "        'threshold': threshold,\n",
    "        'meets_threshold': similarity_score >= threshold,\n",
    "        'missing_skills': list(missing_skills),\n",
    "        'matching_skills': list(matching_skills),\n",
    "        'skill_gap_percentage': round(skill_gap * 100, 1),\n",
    "        'improvement_areas': improvement_areas,\n",
    "        'learning_paths': learning_paths[:5],\n",
    "        'actionable_improvements': improvements\n",
    "    }\n",
    "    \n",
    "    return feedback\n",
    "\n",
    "def format_candidate_feedback(feedback_dict):\n",
    "    \"\"\"\n",
    "    Format candidate feedback as a readable report.\n",
    "    \n",
    "    Args:\n",
    "        feedback_dict: Dictionary from generate_candidate_feedback()\n",
    "    \n",
    "    Returns:\n",
    "        Formatted string report\n",
    "    \"\"\"\n",
    "    report = f\"\"\"\n",
    "{'='*70}\n",
    "CANDIDATE FEEDBACK REPORT\n",
    "{'='*70}\n",
    "\n",
    "Job Position: {feedback_dict['job_title']}\n",
    "Company: {feedback_dict['company']}\n",
    "Candidate ID: {feedback_dict['candidate_id']}\n",
    "\n",
    "CURRENT STATUS\n",
    "{'-'*70}\n",
    "Match Score: {feedback_dict['current_score']:.3f}\n",
    "Threshold: {feedback_dict['threshold']}\n",
    "Status: {'Meets Requirements' if feedback_dict['meets_threshold'] else 'Below Threshold'}\n",
    "\n",
    "SKILLS ANALYSIS\n",
    "{'-'*70}\n",
    "Matching Skills: {len(feedback_dict['matching_skills'])}\n",
    "Missing Skills: {len(feedback_dict['missing_skills'])}\n",
    "Skill Gap: {feedback_dict['skill_gap_percentage']}%\n",
    "\n",
    "WHAT YOU'RE MISSING\n",
    "{'-'*70}\n",
    "\"\"\"\n",
    "    \n",
    "    if feedback_dict['missing_skills']:\n",
    "        report += f\"Critical missing skills:\\n\"\n",
    "        for i, skill in enumerate(feedback_dict['missing_skills'][:10], 1):\n",
    "            report += f\"  {i}. {skill}\\n\"\n",
    "    else:\n",
    "        report += \"No significant missing skills identified.\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "IMPROVEMENT AREAS\n",
    "{'-'*70}\n",
    "\"\"\"\n",
    "    for area in feedback_dict['improvement_areas']:\n",
    "        report += f\"   {area}\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "SUGGESTED LEARNING PATHS\n",
    "{'-'*70}\n",
    "\"\"\"\n",
    "    for path in feedback_dict['learning_paths']:\n",
    "        report += f\"   {path}\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "ACTIONABLE IMPROVEMENTS\n",
    "{'-'*70}\n",
    "\"\"\"\n",
    "    for improvement in feedback_dict['actionable_improvements']:\n",
    "        report += f\"   {improvement}\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "NEXT STEPS\n",
    "{'-'*70}\n",
    "1. Focus on acquiring the top 3-5 missing skills\n",
    "2. Update resume with relevant keywords from job description\n",
    "3. Build portfolio projects demonstrating required skills\n",
    "4. Consider relevant certifications or courses\n",
    "5. Re-apply once improvements are made\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "def get_feedback_for_candidate(job_index, resume_index, model='bert', threshold=0.6):\n",
    "    \"\"\"\n",
    "    Get formatted feedback report for a candidate.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job\n",
    "        resume_index: Index of resume\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "        threshold: Minimum score threshold\n",
    "    \n",
    "    Returns:\n",
    "        Formatted feedback report string\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    if model.lower() == 'bert' and 'find_best_matches_bert' in g:\n",
    "        results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['BERT_Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    elif model.lower() == 'roberta' and 'find_best_matches_roberta' in g:\n",
    "        results = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['RoBERTa_Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run TF-IDF vectorization cell first.\")\n",
    "        results = find_best_matches(job_index, g['resume_tfidf'], g['job_tfidf'], df_resumes_clean, top_n=1000)\n",
    "        if not results.empty:\n",
    "            candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "            if not candidate_results.empty:\n",
    "                score = candidate_results.iloc[0]['Similarity_Score']\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "    \n",
    "    feedback = generate_candidate_feedback(job_index, resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                          score, model_type=model, threshold=threshold)\n",
    "    return format_candidate_feedback(feedback)\n",
    "\n",
    "# Example usage:\n",
    "# feedback = get_feedback_for_candidate(job_index=0, resume_index=100, model='bert', threshold=0.6)\n",
    "# print(feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation Metrics for matching system performance.\n",
    "Includes Accuracy, Precision/Recall, and text generation metrics (ROUGE/BLEU/METEOR).\n",
    "\"\"\"\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    METRICS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    METRICS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from rouge_score import rouge_scorer\n",
    "    ROUGE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ROUGE_AVAILABLE = False\n",
    "    try:\n",
    "        import nltk\n",
    "        nltk.download('punkt', quiet=True)\n",
    "        from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "        from nltk.translate.meteor_score import meteor_score\n",
    "        BLEU_METEOR_AVAILABLE = True\n",
    "    except:\n",
    "        BLEU_METEOR_AVAILABLE = False\n",
    "\n",
    "def evaluate_matching_accuracy(true_matches, predicted_matches, top_k=10):\n",
    "    \"\"\"\n",
    "    Evaluate matching accuracy using ground truth labels.\n",
    "    \n",
    "    Args:\n",
    "        true_matches: Dictionary {job_index: [list of true resume IDs]}\n",
    "        predicted_matches: Dictionary {job_index: DataFrame with predicted matches}\n",
    "        top_k: Number of top predictions to consider\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with accuracy metrics\n",
    "    \"\"\"\n",
    "    if not METRICS_AVAILABLE:\n",
    "        return {\"error\": \"sklearn not available\"}\n",
    "    \n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    \n",
    "    for job_idx in true_matches.keys():\n",
    "        if job_idx in predicted_matches:\n",
    "            true_resume_ids = set(true_matches[job_idx])\n",
    "            pred_df = predicted_matches[job_idx]\n",
    "            \n",
    "            if not pred_df.empty and 'Resume_ID' in pred_df.columns:\n",
    "                pred_resume_ids = set(pred_df.head(top_k)['Resume_ID'].tolist())\n",
    "                \n",
    "                # Binary classification: 1 if in top-k, 0 otherwise\n",
    "                for resume_id in true_resume_ids:\n",
    "                    all_true.append(1)\n",
    "                    all_pred.append(1 if resume_id in pred_resume_ids else 0)\n",
    "    \n",
    "    if len(all_true) == 0:\n",
    "        return {\"error\": \"No matching data available\"}\n",
    "    \n",
    "    accuracy = accuracy_score(all_true, all_pred)\n",
    "    precision = precision_score(all_true, all_pred, zero_division=0)\n",
    "    recall = recall_score(all_true, all_pred, zero_division=0)\n",
    "    f1 = f1_score(all_true, all_pred, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': round(accuracy, 3),\n",
    "        'precision': round(precision, 3),\n",
    "        'recall': round(recall, 3),\n",
    "        'f1_score': round(f1, 3),\n",
    "        'total_samples': len(all_true)\n",
    "    }\n",
    "\n",
    "def calculate_rouge_score(reference, generated):\n",
    "    \"\"\"\n",
    "    Calculate ROUGE scores for generated text evaluation.\n",
    "    \n",
    "    Args:\n",
    "        reference: Reference text string\n",
    "        generated: Generated text string\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with ROUGE-1, ROUGE-2, ROUGE-L scores\n",
    "    \"\"\"\n",
    "    if not ROUGE_AVAILABLE:\n",
    "        return {\"error\": \"rouge_score library not available. Install with: pip install rouge-score\"}\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "    \n",
    "    return {\n",
    "        'rouge1': {\n",
    "            'precision': round(scores['rouge1'].precision, 3),\n",
    "            'recall': round(scores['rouge1'].recall, 3),\n",
    "            'fmeasure': round(scores['rouge1'].fmeasure, 3)\n",
    "        },\n",
    "        'rouge2': {\n",
    "            'precision': round(scores['rouge2'].precision, 3),\n",
    "            'recall': round(scores['rouge2'].recall, 3),\n",
    "            'fmeasure': round(scores['rouge2'].fmeasure, 3)\n",
    "        },\n",
    "        'rougeL': {\n",
    "            'precision': round(scores['rougeL'].precision, 3),\n",
    "            'recall': round(scores['rougeL'].recall, 3),\n",
    "            'fmeasure': round(scores['rougeL'].fmeasure, 3)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def calculate_bleu_meteor(reference, generated):\n",
    "    \"\"\"\n",
    "    Calculate BLEU and METEOR scores for text evaluation.\n",
    "    \n",
    "    Args:\n",
    "        reference: Reference text (string or list of tokens)\n",
    "        generated: Generated text (string or list of tokens)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with BLEU and METEOR scores\n",
    "    \"\"\"\n",
    "    if not BLEU_METEOR_AVAILABLE:\n",
    "        return {\"error\": \"NLTK not properly configured\"}\n",
    "    \n",
    "    try:\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        \n",
    "        if isinstance(reference, str):\n",
    "            ref_tokens = word_tokenize(reference.lower())\n",
    "        else:\n",
    "            ref_tokens = reference\n",
    "        \n",
    "        if isinstance(generated, str):\n",
    "            gen_tokens = word_tokenize(generated.lower())\n",
    "        else:\n",
    "            gen_tokens = generated\n",
    "        \n",
    "        smoothing = SmoothingFunction().method1\n",
    "        bleu = sentence_bleu([ref_tokens], gen_tokens, smoothing_function=smoothing)\n",
    "        \n",
    "        meteor = meteor_score([ref_tokens], gen_tokens)\n",
    "        \n",
    "        return {\n",
    "            'bleu': round(bleu, 3),\n",
    "            'meteor': round(meteor, 3)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def evaluate_summary_quality(summary_text, reference_summary=None):\n",
    "    \"\"\"\n",
    "    Evaluate quality of generated match summaries using ROUGE, BLEU, METEOR.\n",
    "    \n",
    "    Args:\n",
    "        summary_text: Generated summary text\n",
    "        reference_summary: Reference summary for comparison (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if reference_summary:\n",
    "        rouge_scores = calculate_rouge_score(reference_summary, summary_text)\n",
    "        results['rouge'] = rouge_scores\n",
    "        \n",
    "        bleu_meteor = calculate_bleu_meteor(reference_summary, summary_text)\n",
    "        results['bleu_meteor'] = bleu_meteor\n",
    "    else:\n",
    "        results['note'] = \"Reference summary not provided. Cannot calculate ROUGE/BLEU/METEOR.\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "def comprehensive_evaluation(job_index, top_n=10, model='bert'):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of matching system for a specific job.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job to evaluate\n",
    "        top_n: Number of top matches to evaluate\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with comprehensive evaluation metrics\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    job = df_jobs_clean.iloc[job_index]\n",
    "    job_category_keywords = job.get('Category', '').lower() if 'Category' in job else ''\n",
    "    \n",
    "    # Get predictions\n",
    "    if model.lower() == 'bert' and 'find_best_matches_bert' in g:\n",
    "        predictions = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "    elif model.lower() == 'roberta' and 'find_best_matches_roberta' in g:\n",
    "        predictions = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing.\")\n",
    "        predictions = find_best_matches(job_index, g['resume_tfidf'], g['job_tfidf'], df_resumes_clean, top_n=top_n)\n",
    "    \n",
    "    if predictions.empty:\n",
    "        return {\"error\": \"No predictions generated\"}\n",
    "    \n",
    "    # Category-based evaluation (assuming category match is a proxy for correctness)\n",
    "    if 'Category' in predictions.columns and 'Category' in df_resumes_clean.columns:\n",
    "        predicted_categories = predictions['Category'].tolist()\n",
    "        job_category = job.get('Category', '')\n",
    "        \n",
    "        # Calculate category match rate\n",
    "        category_matches = sum(1 for cat in predicted_categories if cat == job_category)\n",
    "        category_accuracy = category_matches / len(predicted_categories) if predicted_categories else 0\n",
    "        \n",
    "        # Calculate average similarity score\n",
    "        score_col = 'BERT_Similarity_Score' if 'BERT_Similarity_Score' in predictions.columns else \\\n",
    "                   'RoBERTa_Similarity_Score' if 'RoBERTa_Similarity_Score' in predictions.columns else \\\n",
    "                   'Similarity_Score'\n",
    "        avg_score = predictions[score_col].mean()\n",
    "        max_score = predictions[score_col].max()\n",
    "        min_score = predictions[score_col].min()\n",
    "    else:\n",
    "        category_accuracy = 0\n",
    "        score_col = 'Similarity_Score'\n",
    "        avg_score = predictions[score_col].mean() if score_col in predictions.columns else 0\n",
    "        max_score = predictions[score_col].max() if score_col in predictions.columns else 0\n",
    "        min_score = predictions[score_col].min() if score_col in predictions.columns else 0\n",
    "    \n",
    "    # Generate sample summary and evaluate\n",
    "    sample_resume_idx = 0\n",
    "    try:\n",
    "        sample_summary = get_match_summary_for_candidate(job_index, sample_resume_idx, model=model)\n",
    "        summary_length = len(sample_summary.split())\n",
    "    except:\n",
    "        sample_summary = \"\"\n",
    "        summary_length = 0\n",
    "    \n",
    "    evaluation = {\n",
    "        'job_index': job_index,\n",
    "        'job_title': job.get('Title', 'N/A'),\n",
    "        'model_used': model.upper(),\n",
    "        'top_n': top_n,\n",
    "        'category_accuracy': round(category_accuracy, 3),\n",
    "        'average_similarity': round(avg_score, 3),\n",
    "        'max_similarity': round(max_score, 3),\n",
    "        'min_similarity': round(min_score, 3),\n",
    "        'summary_length': summary_length,\n",
    "        'predictions_count': len(predictions)\n",
    "    }\n",
    "    \n",
    "    return evaluation\n",
    "\n",
    "# Example usage:\n",
    "# eval_results = comprehensive_evaluation(job_index=0, top_n=10, model='bert')\n",
    "# print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ETHICAL CONSIDERATIONS & RESPONSIBLE AI\n",
      "======================================================================\n",
      "\n",
      "1. BIAS MITIGATION\n",
      "----------------------------------------------------------------------\n",
      "Potential Biases Identified:\n",
      "   Gender bias: Model may favor certain gender-associated terms\n",
      "   Cultural bias: Language patterns may favor certain cultural backgrounds\n",
      "  Educational bias: Over-reliance on specific institutions or credentials\n",
      "   Experience bias: May favor candidates with more keywords over actual experience\n",
      "\n",
      "Mitigation Strategies:\n",
      "   Use multiple models (BERT, RoBERTa, TF-IDF) to reduce single-model bias\n",
      "   Skill-based matching reduces reliance on demographic indicators\n",
      "   Transparent scoring allows human review of automated decisions\n",
      "   Regular model auditing and bias testing recommended\n",
      "   Diverse training data representation\n",
      "\n",
      "2. FAIRNESS\n",
      "----------------------------------------------------------------------\n",
      "Fairness Measures Implemented:\n",
      "   Objective similarity scoring based on content, not demographics\n",
      "   Multiple evaluation criteria (semantic + skills) for balanced assessment\n",
      "   Threshold-based filtering allows consistent application\n",
      "   Category-agnostic matching (does not explicitly filter by candidate category)\n",
      "\n",
      "Fairness Concerns:\n",
      "   Model may still encode societal biases from training data\n",
      "   Skill extraction may favor certain terminology styles\n",
      "   No explicit demographic fairness checks implemented\n",
      "\n",
      "Recommendations:\n",
      "   Implement demographic parity monitoring\n",
      "   Add fairness metrics (equalized odds, demographic parity)\n",
      "   Regular bias audits on matched candidates\n",
      "   Human-in-the-loop for final hiring decisions\n",
      "\n",
      "3. EXPLAINABILITY\n",
      "----------------------------------------------------------------------\n",
      "Explainability Features:\n",
      "   Match summaries provide clear reasoning for recommendations\n",
      "   Skill overlap analysis shows specific matching criteria\n",
      "   Similarity scores are transparent and interpretable\n",
      "   Feedback reports explain why candidates don't match\n",
      "\n",
      "Limitations:\n",
      "   Deep learning models (BERT/RoBERTa) are black boxes\n",
      "   Feature importance not explicitly shown\n",
      "   Decision boundaries not clearly defined\n",
      "\n",
      "Improvements Needed:\n",
      "   Add SHAP/LIME explanations for model decisions\n",
      "   Highlight most influential words/phrases in matching\n",
      "   Provide confidence intervals for scores\n",
      "   Visualize decision process flow\n",
      "\n",
      "4. RESPONSIBLE AI PRACTICES\n",
      "----------------------------------------------------------------------\n",
      "Current Practices:\n",
      "   Human oversight: System provides recommendations, not final decisions\n",
      "   Transparency: All scores and criteria are visible\n",
      "   Accountability: Clear documentation of matching logic\n",
      "   Privacy: No personal information stored beyond resume content\n",
      "\n",
      "Best Practices Implemented:\n",
      "   Multiple model ensemble reduces single-point-of-failure\n",
      "   Caching system ensures consistent results\n",
      "   Error handling prevents silent failures\n",
      "   Comprehensive logging for audit trails\n",
      "\n",
      "Areas for Improvement:\n",
      "   Add consent mechanisms for data usage\n",
      "   Implement data retention policies\n",
      "   Regular model performance monitoring\n",
      "   Bias testing framework\n",
      "   User feedback collection mechanism\n",
      "\n",
      "5. DATA PRIVACY & SECURITY\n",
      "----------------------------------------------------------------------\n",
      "Privacy Measures:\n",
      "   Resume data processed locally (no external API calls for matching)\n",
      "   Cached data stored securely in local files\n",
      "   No personally identifiable information (PII) in logs\n",
      "   Optional anonymization before processing\n",
      "\n",
      "Security Considerations:\n",
      "   Input validation prevents injection attacks\n",
      "   File access restricted to necessary operations\n",
      "   No network transmission of sensitive data during matching\n",
      "\n",
      "6. ACCOUNTABILITY & GOVERNANCE\n",
      "----------------------------------------------------------------------\n",
      "Accountability Framework:\n",
      "   Clear documentation of system limitations\n",
      "   Transparent scoring methodology\n",
      "   Audit trail through match summaries\n",
      "   Human review required for final decisions\n",
      "\n",
      "Governance Recommendations:\n",
      "   Regular model performance reviews\n",
      "   Bias audit schedule (quarterly recommended)\n",
      "   Stakeholder feedback integration\n",
      "   Continuous improvement process\n",
      "   Compliance with employment regulations\n",
      "\n",
      "7. LIMITATIONS & DISCLAIMERS\n",
      "----------------------------------------------------------------------\n",
      "System Limitations:\n",
      "   AI matching is a tool, not a replacement for human judgment\n",
      "   Scores may not reflect all relevant factors (personality, culture fit)\n",
      "   Model trained on historical data may perpetuate existing biases\n",
      "   Language model limitations may miss nuanced qualifications\n",
      "   No guarantee of perfect matches or hiring success\n",
      "\n",
      "Recommended Usage:\n",
      "   Use as initial screening tool to reduce manual review time\n",
      "   Always include human review for final hiring decisions\n",
      "   Consider multiple factors beyond AI scores\n",
      "   Regularly update and retrain models with new data\n",
      "   Monitor for bias and adjust thresholds as needed\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ethical Considerations and Responsible AI Discussion.\n",
    "Covers bias, fairness, explainability, and responsible AI practices.\n",
    "\"\"\"\n",
    "def ethical_considerations_report():\n",
    "    \"\"\"\n",
    "    Generate comprehensive ethical considerations report for the AI recruitment system.\n",
    "    \n",
    "    Returns:\n",
    "        Formatted report on ethical considerations\n",
    "    \"\"\"\n",
    "    report = f\"\"\"\n",
    "{'='*70}\n",
    "ETHICAL CONSIDERATIONS & RESPONSIBLE AI\n",
    "{'='*70}\n",
    "\n",
    "1. BIAS MITIGATION\n",
    "{'-'*70}\n",
    "Potential Biases Identified:\n",
    "   Gender bias: Model may favor certain gender-associated terms\n",
    "   Cultural bias: Language patterns may favor certain cultural backgrounds\n",
    "  Educational bias: Over-reliance on specific institutions or credentials\n",
    "   Experience bias: May favor candidates with more keywords over actual experience\n",
    "\n",
    "Mitigation Strategies:\n",
    "   Use multiple models (BERT, RoBERTa, TF-IDF) to reduce single-model bias\n",
    "   Skill-based matching reduces reliance on demographic indicators\n",
    "   Transparent scoring allows human review of automated decisions\n",
    "   Regular model auditing and bias testing recommended\n",
    "   Diverse training data representation\n",
    "\n",
    "2. FAIRNESS\n",
    "{'-'*70}\n",
    "Fairness Measures Implemented:\n",
    "   Objective similarity scoring based on content, not demographics\n",
    "   Multiple evaluation criteria (semantic + skills) for balanced assessment\n",
    "   Threshold-based filtering allows consistent application\n",
    "   Category-agnostic matching (does not explicitly filter by candidate category)\n",
    "\n",
    "Fairness Concerns:\n",
    "   Model may still encode societal biases from training data\n",
    "   Skill extraction may favor certain terminology styles\n",
    "   No explicit demographic fairness checks implemented\n",
    "\n",
    "Recommendations:\n",
    "   Implement demographic parity monitoring\n",
    "   Add fairness metrics (equalized odds, demographic parity)\n",
    "   Regular bias audits on matched candidates\n",
    "   Human-in-the-loop for final hiring decisions\n",
    "\n",
    "3. EXPLAINABILITY\n",
    "{'-'*70}\n",
    "Explainability Features:\n",
    "   Match summaries provide clear reasoning for recommendations\n",
    "   Skill overlap analysis shows specific matching criteria\n",
    "   Similarity scores are transparent and interpretable\n",
    "   Feedback reports explain why candidates don't match\n",
    "\n",
    "Limitations:\n",
    "   Deep learning models (BERT/RoBERTa) are black boxes\n",
    "   Feature importance not explicitly shown\n",
    "   Decision boundaries not clearly defined\n",
    "\n",
    "Improvements Needed:\n",
    "   Add SHAP/LIME explanations for model decisions\n",
    "   Highlight most influential words/phrases in matching\n",
    "   Provide confidence intervals for scores\n",
    "   Visualize decision process flow\n",
    "\n",
    "4. RESPONSIBLE AI PRACTICES\n",
    "{'-'*70}\n",
    "Current Practices:\n",
    "   Human oversight: System provides recommendations, not final decisions\n",
    "   Transparency: All scores and criteria are visible\n",
    "   Accountability: Clear documentation of matching logic\n",
    "   Privacy: No personal information stored beyond resume content\n",
    "\n",
    "Best Practices Implemented:\n",
    "   Multiple model ensemble reduces single-point-of-failure\n",
    "   Caching system ensures consistent results\n",
    "   Error handling prevents silent failures\n",
    "   Comprehensive logging for audit trails\n",
    "\n",
    "Areas for Improvement:\n",
    "   Add consent mechanisms for data usage\n",
    "   Implement data retention policies\n",
    "   Regular model performance monitoring\n",
    "   Bias testing framework\n",
    "   User feedback collection mechanism\n",
    "\n",
    "5. DATA PRIVACY & SECURITY\n",
    "{'-'*70}\n",
    "Privacy Measures:\n",
    "   Resume data processed locally (no external API calls for matching)\n",
    "   Cached data stored securely in local files\n",
    "   No personally identifiable information (PII) in logs\n",
    "   Optional anonymization before processing\n",
    "\n",
    "Security Considerations:\n",
    "   Input validation prevents injection attacks\n",
    "   File access restricted to necessary operations\n",
    "   No network transmission of sensitive data during matching\n",
    "\n",
    "6. ACCOUNTABILITY & GOVERNANCE\n",
    "{'-'*70}\n",
    "Accountability Framework:\n",
    "   Clear documentation of system limitations\n",
    "   Transparent scoring methodology\n",
    "   Audit trail through match summaries\n",
    "   Human review required for final decisions\n",
    "\n",
    "Governance Recommendations:\n",
    "   Regular model performance reviews\n",
    "   Bias audit schedule (quarterly recommended)\n",
    "   Stakeholder feedback integration\n",
    "   Continuous improvement process\n",
    "   Compliance with employment regulations\n",
    "\n",
    "7. LIMITATIONS & DISCLAIMERS\n",
    "{'-'*70}\n",
    "System Limitations:\n",
    "   AI matching is a tool, not a replacement for human judgment\n",
    "   Scores may not reflect all relevant factors (personality, culture fit)\n",
    "   Model trained on historical data may perpetuate existing biases\n",
    "   Language model limitations may miss nuanced qualifications\n",
    "   No guarantee of perfect matches or hiring success\n",
    "\n",
    "Recommended Usage:\n",
    "   Use as initial screening tool to reduce manual review time\n",
    "   Always include human review for final hiring decisions\n",
    "   Consider multiple factors beyond AI scores\n",
    "   Regularly update and retrain models with new data\n",
    "   Monitor for bias and adjust thresholds as needed\n",
    "\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "    return report\n",
    "\n",
    "def print_ethical_considerations():\n",
    "    \"\"\"Print the ethical considerations report.\"\"\"\n",
    "    print(ethical_considerations_report())\n",
    "\n",
    "# Generate and display ethical considerations\n",
    "print_ethical_considerations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete Job-Resume Evaluation System\n",
    "Generates all three required outputs: similarity score, match summary, and feedback report.\n",
    "\"\"\"\n",
    "def complete_job_resume_evaluation(job_index, resume_index, model='bert', threshold=0.6):\n",
    "    \"\"\"\n",
    "    Complete evaluation system that generates all three required outputs:\n",
    "    1. Similarity Score\n",
    "    2. Match Summary for hiring managers\n",
    "    3. Feedback report for candidates\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job in df_jobs_clean\n",
    "        resume_index: Index of resume in df_resumes_clean\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "        threshold: Minimum score threshold\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing all three outputs\n",
    "    \"\"\"\n",
    "    g = globals()\n",
    "    \n",
    "    if 'df_jobs_clean' not in g or 'df_resumes_clean' not in g:\n",
    "        raise RuntimeError(\"df_jobs_clean or df_resumes_clean not found. Run preprocessing cells first.\")\n",
    "    \n",
    "    df_jobs_clean = g['df_jobs_clean']\n",
    "    df_resumes_clean = g['df_resumes_clean']\n",
    "    \n",
    "    # Calculate similarity score\n",
    "    if model.lower() == 'bert' and 'find_best_matches_bert' in g:\n",
    "        results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        score_col = 'BERT_Similarity_Score'\n",
    "    elif model.lower() == 'roberta' and 'find_best_matches_roberta' in g:\n",
    "        results = find_best_matches_roberta(job_index, df_jobs_clean, df_resumes_clean, top_n=1000)\n",
    "        score_col = 'RoBERTa_Similarity_Score'\n",
    "    else:\n",
    "        if 'job_tfidf' not in g or 'resume_tfidf' not in g:\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing.\")\n",
    "        results = find_best_matches(job_index, g['resume_tfidf'], g['job_tfidf'], df_resumes_clean, top_n=1000)\n",
    "        score_col = 'Similarity_Score'\n",
    "    \n",
    "    if not results.empty:\n",
    "        candidate_results = results[results['Resume_ID'] == df_resumes_clean.iloc[resume_index]['ID']]\n",
    "        if not candidate_results.empty:\n",
    "            similarity_score = candidate_results.iloc[0][score_col]\n",
    "        else:\n",
    "            similarity_score = 0.0\n",
    "    else:\n",
    "        similarity_score = 0.0\n",
    "    \n",
    "    # Generate match summary\n",
    "    summary_dict = generate_match_summary(job_index, resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                         similarity_score, model_type=model, threshold=threshold)\n",
    "    match_summary = format_match_summary(summary_dict)\n",
    "    \n",
    "    # Generate feedback report\n",
    "    feedback_dict = generate_candidate_feedback(job_index, resume_index, df_jobs_clean, df_resumes_clean, \n",
    "                                                similarity_score, model_type=model, threshold=threshold)\n",
    "    feedback_report = format_candidate_feedback(feedback_dict)\n",
    "    \n",
    "    return {\n",
    "        'similarity_score': round(similarity_score, 3),\n",
    "        'match_summary': match_summary,\n",
    "        'feedback_report': feedback_report,\n",
    "        'meets_threshold': similarity_score >= threshold,\n",
    "        'summary_dict': summary_dict,\n",
    "        'feedback_dict': feedback_dict\n",
    "    }\n",
    "\n",
    "def display_complete_evaluation(job_index, resume_index, model='bert', threshold=0.6):\n",
    "    \"\"\"\n",
    "    Display all three outputs in a formatted way.\n",
    "    \n",
    "    Args:\n",
    "        job_index: Index of job\n",
    "        resume_index: Index of resume\n",
    "        model: 'bert', 'roberta', or 'tfidf'\n",
    "        threshold: Minimum score threshold\n",
    "    \"\"\"\n",
    "    results = complete_job_resume_evaluation(job_index, resume_index, model=model, threshold=threshold)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPLETE JOB-RESUME EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n1. SIMILARITY SCORE: {results['similarity_score']:.3f}\")\n",
    "    print(f\"   Threshold: {threshold}\")\n",
    "    print(f\"   Status: {'PASS' if results['meets_threshold'] else 'FAIL'}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"2. MATCH SUMMARY (For Hiring Managers)\")\n",
    "    print(\"=\"*70)\n",
    "    print(results['match_summary'])\n",
    "    \n",
    "    if not results['meets_threshold']:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"3. FEEDBACK REPORT (For Candidate)\")\n",
    "        print(\"=\"*70)\n",
    "        print(results['feedback_report'])\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"3. FEEDBACK REPORT (For Candidate)\")\n",
    "        print(\"=\"*70)\n",
    "        print(\"Candidate meets threshold. Feedback report available upon request.\")\n",
    "        print(results['feedback_report'])\n",
    "\n",
    "# Example usage:\n",
    "# display_complete_evaluation(job_index=0, resume_index=0, model='bert', threshold=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RoBERTa MODEL VERIFICATION\n",
      "============================================================\n",
      "RoBERTa model: Available\n",
      "Model type: <class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n",
      "\n",
      "Testing RoBERTa similarity:\n",
      "  'software engineer'  'developer': 0.526\n",
      "\n",
      "Testing RoBERTa matching:\n",
      "  Found 3 matches\n",
      "  Top match score: 0.843\n",
      "\n",
      "RoBERTa is ready to use!\n",
      "\n",
      "Example usage:\n",
      "  get_top_n_jobs_for_resume(resume_index=0, n=10, model='roberta')\n",
      "  get_top_n_resumes_for_job(job_index=0, n=10, model='roberta')\n",
      "  compare_matching_methods(job_index=0, top_n=5)  # Includes RoBERTa\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RoBERTa Model Verification and Testing\n",
    "\"\"\"\n",
    "print(\"=\" * 60)\n",
    "print(\"RoBERTa MODEL VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'roberta_model' in globals() and roberta_model is not None:\n",
    "    print(\"RoBERTa model: Available\")\n",
    "    print(f\"Model type: {type(roberta_model)}\")\n",
    "    \n",
    "    # Test similarity calculation\n",
    "    print(\"\\nTesting RoBERTa similarity:\")\n",
    "    test_sim = calculate_roberta_similarity(\"software engineer\", \"developer\")\n",
    "    print(f\"  'software engineer'  'developer': {test_sim:.3f}\")\n",
    "    \n",
    "    # Test matching if data is available\n",
    "    if 'df_jobs_clean' in globals() and 'df_resumes_clean' in globals():\n",
    "        print(\"\\nTesting RoBERTa matching:\")\n",
    "        try:\n",
    "            roberta_test = find_best_matches_roberta(0, df_jobs_clean, df_resumes_clean, top_n=3)\n",
    "            if not roberta_test.empty:\n",
    "                print(f\"  Found {len(roberta_test)} matches\")\n",
    "                print(f\"  Top match score: {roberta_test.iloc[0]['RoBERTa_Similarity_Score']:.3f}\")\n",
    "            else:\n",
    "                print(\"  No matches found\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Matching test failed: {e}\")\n",
    "    \n",
    "    print(\"\\nRoBERTa is ready to use!\")\n",
    "    print(\"\\nExample usage:\")\n",
    "    print(\"  get_top_n_jobs_for_resume(resume_index=0, n=10, model='roberta')\")\n",
    "    print(\"  get_top_n_resumes_for_job(job_index=0, n=10, model='roberta')\")\n",
    "    print(\"  compare_matching_methods(job_index=0, top_n=5)  # Includes RoBERTa\")\n",
    "else:\n",
    "    print(\"RoBERTa model: NOT AVAILABLE\")\n",
    "    print(\"Possible reasons:\")\n",
    "    print(\"  1. Model initialization failed (check error messages above)\")\n",
    "    print(\"  2. transformers library not installed\")\n",
    "    print(\"  3. Model download failed\")\n",
    "    print(\"\\nTo fix: Re-run Cell 7 to initialize RoBERTa model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume [1000]  ID: 40987524 | Category: SALES\n",
      "Resume preview:          SALES       Summary    Over 17 years of sales and operations management experience in specialty and big-box retail and 4 years sales experien...\n",
      "\n",
      "Top 10 matching jobs (RoBERTa):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Score</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sales Manager</td>\n",
       "      <td>Ameria CJSC</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>On behalf of its partner, Ameria CJSC is seeking\\r\\napplicants for the position of Sales Manager...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Care Manager</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.637438</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Customer Care Manager</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.632793</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Customer Care Manager</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.632793</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Customer Care Manager</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.632793</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Sales &amp; Marketing Manager</td>\n",
       "      <td>Ard Style</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.624279</td>\n",
       "      <td>Ard Style is looking for an experienced Sales and\\r\\nMarketing Manager to be responsible for dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Marketing Advisor</td>\n",
       "      <td>ACDI/VOCA</td>\n",
       "      <td>Tbilisi, Georgia</td>\n",
       "      <td>0.623824</td>\n",
       "      <td>The Marketing Advisor will lead the project in\\r\\nidentifying and developing market opportunitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Customer Care Co-ordinator</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.612038</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Customer Care Co-ordinator</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.612038</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Customer Care Co-ordinator</td>\n",
       "      <td>Lycos Europe</td>\n",
       "      <td>Yerevan, Armenia</td>\n",
       "      <td>0.612038</td>\n",
       "      <td>To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                       Title       Company          Location     Score  \\\n",
       "0     1               Sales Manager   Ameria CJSC  Yerevan, Armenia  0.641577   \n",
       "1     2       Customer Care Manager  Lycos Europe  Yerevan, Armenia  0.637438   \n",
       "2     3       Customer Care Manager  Lycos Europe  Yerevan, Armenia  0.632793   \n",
       "3     4       Customer Care Manager  Lycos Europe  Yerevan, Armenia  0.632793   \n",
       "4     5       Customer Care Manager  Lycos Europe  Yerevan, Armenia  0.632793   \n",
       "5     6   Sales & Marketing Manager     Ard Style  Yerevan, Armenia  0.624279   \n",
       "6     7           Marketing Advisor     ACDI/VOCA  Tbilisi, Georgia  0.623824   \n",
       "7     8  Customer Care Co-ordinator  Lycos Europe  Yerevan, Armenia  0.612038   \n",
       "8     9  Customer Care Co-ordinator  Lycos Europe  Yerevan, Armenia  0.612038   \n",
       "9    10  Customer Care Co-ordinator  Lycos Europe  Yerevan, Armenia  0.612038   \n",
       "\n",
       "                                                                                           Description  \n",
       "0  On behalf of its partner, Ameria CJSC is seeking\\r\\napplicants for the position of Sales Manager...  \n",
       "1  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "2  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "3  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "4  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "5  Ard Style is looking for an experienced Sales and\\r\\nMarketing Manager to be responsible for dev...  \n",
       "6  The Marketing Advisor will lead the project in\\r\\nidentifying and developing market opportunitie...  \n",
       "7  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "8  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  \n",
       "9  To build up our European Sales Support Team in\\r\\nArmenia, we are currently looking to recruit s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jobs_for_candidate = find_jobs_for_candidate(resume_index=1000, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE JOB-RESUME EVALUATION\n",
      "======================================================================\n",
      "\n",
      "1. SIMILARITY SCORE: 0.489\n",
      "   Threshold: 0.6\n",
      "   Status: FAIL\n",
      "\n",
      "======================================================================\n",
      "2. MATCH SUMMARY (For Hiring Managers)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MATCH SUMMARY REPORT\n",
      "======================================================================\n",
      "\n",
      "Job Position: Chief Financial Officer\n",
      "Company: AMERIA Investment Consulting Company\n",
      "Candidate ID: 16852973\n",
      "Candidate Category: HR\n",
      "\n",
      "OVERALL ASSESSMENT\n",
      "----------------------------------------------------------------------\n",
      "Similarity Score: 0.489\n",
      "Alignment Level: Weak Match\n",
      "Recommendation: Not Recommended\n",
      "\n",
      "WHY THIS CANDIDATE IS A FIT\n",
      "----------------------------------------------------------------------\n",
      "Candidate demonstrates 48.9% semantic alignment with the job requirements. Skill overlap of 32.6% indicates relevant experience.\n",
      "\n",
      "SKILLS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "Matching Skills (10): skill, administration, procedure, leadership, year, law, analysis, budgeting, activity, office\n",
      "Skill Match Ratio: 32.6%\n",
      "\n",
      "GAPS IDENTIFIED\n",
      "----------------------------------------------------------------------\n",
      "Missing 97 key skills: return, covenant, work, individual, projection\n",
      "\n",
      "ADDITIONAL SKILLS\n",
      "----------------------------------------------------------------------\n",
      "Candidate has 10 additional skills: multi, marketing, provider, seminar, resolution\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "3. FEEDBACK REPORT (For Candidate)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CANDIDATE FEEDBACK REPORT\n",
      "======================================================================\n",
      "\n",
      "Job Position: Chief Financial Officer\n",
      "Company: AMERIA Investment Consulting Company\n",
      "Candidate ID: 16852973\n",
      "\n",
      "CURRENT STATUS\n",
      "----------------------------------------------------------------------\n",
      "Match Score: 0.489\n",
      "Threshold: 0.6\n",
      "Status: Below Threshold\n",
      "\n",
      "SKILLS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "Matching Skills: 47\n",
      "Missing Skills: 97\n",
      "Skill Gap: 67.4%\n",
      "\n",
      "WHAT YOU'RE MISSING\n",
      "----------------------------------------------------------------------\n",
      "Critical missing skills:\n",
      "  1. return\n",
      "  2. covenant\n",
      "  3. work\n",
      "  4. individual\n",
      "  5. projection\n",
      "  6. word\n",
      "  7. principle\n",
      "  8. concentration\n",
      "  9. legislation\n",
      "  10. change\n",
      "\n",
      "IMPROVEMENT AREAS\n",
      "----------------------------------------------------------------------\n",
      "   Overall profile alignment needs improvement\n",
      "   Missing 97 critical skills\n",
      "\n",
      "SUGGESTED LEARNING PATHS\n",
      "----------------------------------------------------------------------\n",
      "   return: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   covenant: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   work: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   individual: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   projection: Consider online courses (Coursera, Udemy) or certification programs\n",
      "\n",
      "ACTIONABLE IMPROVEMENTS\n",
      "----------------------------------------------------------------------\n",
      "   Enhance resume keywords to better match job description terminology\n",
      "   Focus on acquiring top 5 missing skills: return, covenant, work, individual, projection\n",
      "   Highlight relevant projects and experiences more prominently\n",
      "   Consider obtaining relevant certifications to strengthen profile\n",
      "\n",
      "NEXT STEPS\n",
      "----------------------------------------------------------------------\n",
      "1. Focus on acquiring the top 3-5 missing skills\n",
      "2. Update resume with relevant keywords from job description\n",
      "3. Build portfolio projects demonstrating required skills\n",
      "4. Consider relevant certifications or courses\n",
      "5. Re-apply once improvements are made\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "MATCH SUMMARY REPORT\n",
      "======================================================================\n",
      "\n",
      "Job Position: Chief Financial Officer\n",
      "Company: AMERIA Investment Consulting Company\n",
      "Candidate ID: 16852973\n",
      "Candidate Category: HR\n",
      "\n",
      "OVERALL ASSESSMENT\n",
      "----------------------------------------------------------------------\n",
      "Similarity Score: 0.489\n",
      "Alignment Level: Weak Match\n",
      "Recommendation: Not Recommended\n",
      "\n",
      "WHY THIS CANDIDATE IS A FIT\n",
      "----------------------------------------------------------------------\n",
      "Candidate demonstrates 48.9% semantic alignment with the job requirements. Skill overlap of 32.6% indicates relevant experience.\n",
      "\n",
      "SKILLS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "Matching Skills (10): skill, administration, procedure, leadership, year, law, analysis, budgeting, activity, office\n",
      "Skill Match Ratio: 32.6%\n",
      "\n",
      "GAPS IDENTIFIED\n",
      "----------------------------------------------------------------------\n",
      "Missing 97 key skills: return, covenant, work, individual, projection\n",
      "\n",
      "ADDITIONAL SKILLS\n",
      "----------------------------------------------------------------------\n",
      "Candidate has 10 additional skills: multi, marketing, provider, seminar, resolution\n",
      "\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CANDIDATE FEEDBACK REPORT\n",
      "======================================================================\n",
      "\n",
      "Job Position: Chief Financial Officer\n",
      "Company: AMERIA Investment Consulting Company\n",
      "Candidate ID: 10694288\n",
      "\n",
      "CURRENT STATUS\n",
      "----------------------------------------------------------------------\n",
      "Match Score: 0.000\n",
      "Threshold: 0.6\n",
      "Status: Below Threshold\n",
      "\n",
      "SKILLS ANALYSIS\n",
      "----------------------------------------------------------------------\n",
      "Matching Skills: 34\n",
      "Missing Skills: 110\n",
      "Skill Gap: 76.4%\n",
      "\n",
      "WHAT YOU'RE MISSING\n",
      "----------------------------------------------------------------------\n",
      "Critical missing skills:\n",
      "  1. covenant\n",
      "  2. individual\n",
      "  3. projection\n",
      "  4. word\n",
      "  5. principle\n",
      "  6. concentration\n",
      "  7. legislation\n",
      "  8. issue\n",
      "  9. operation\n",
      "  10. executive\n",
      "\n",
      "IMPROVEMENT AREAS\n",
      "----------------------------------------------------------------------\n",
      "   Overall profile alignment needs improvement\n",
      "   Missing 110 critical skills\n",
      "\n",
      "SUGGESTED LEARNING PATHS\n",
      "----------------------------------------------------------------------\n",
      "   covenant: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   individual: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   projection: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   word: Consider online courses (Coursera, Udemy) or certification programs\n",
      "   principle: Consider online courses (Coursera, Udemy) or certification programs\n",
      "\n",
      "ACTIONABLE IMPROVEMENTS\n",
      "----------------------------------------------------------------------\n",
      "   Enhance resume keywords to better match job description terminology\n",
      "   Focus on acquiring top 5 missing skills: covenant, individual, projection, word, principle\n",
      "   Highlight relevant projects and experiences more prominently\n",
      "   Consider obtaining relevant certifications to strengthen profile\n",
      "\n",
      "NEXT STEPS\n",
      "----------------------------------------------------------------------\n",
      "1. Focus on acquiring the top 3-5 missing skills\n",
      "2. Update resume with relevant keywords from job description\n",
      "3. Build portfolio projects demonstrating required skills\n",
      "4. Consider relevant certifications or courses\n",
      "5. Re-apply once improvements are made\n",
      "\n",
      "======================================================================\n",
      "\n",
      "{'job_index': 0, 'job_title': 'Chief Financial Officer', 'model_used': 'BERT', 'top_n': 10, 'category_accuracy': 0.0, 'average_similarity': np.float32(0.728), 'max_similarity': np.float32(0.752), 'min_similarity': np.float32(0.715), 'summary_length': 103, 'predictions_count': 10}\n"
     ]
    }
   ],
   "source": [
    "# Complete evaluation with all three outputs\n",
    "display_complete_evaluation(job_index=0, resume_index=0, model='bert', threshold=0.6)\n",
    "\n",
    "# Just match summary\n",
    "summary = get_match_summary_for_candidate(job_index=0, resume_index=0, model='bert')\n",
    "print(summary)\n",
    "\n",
    "# Just feedback report\n",
    "feedback = get_feedback_for_candidate(job_index=0, resume_index=100, model='bert', threshold=0.6)\n",
    "print(feedback)\n",
    "\n",
    "# Evaluation metrics\n",
    "eval_results = comprehensive_evaluation(job_index=0, top_n=10, model='bert')\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
