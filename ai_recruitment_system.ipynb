{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Assisted Recruitment System\n",
    "\n",
    "This notebook implements an AI-powered recruitment system that matches job postings with resumes using natural language processing and machine learning techniques.\n",
    "\n",
    "## Features:\n",
    "- Job posting analysis and cleaning\n",
    "- Resume parsing and skill extraction\n",
    "- Intelligent job-resume matching\n",
    "- Scoring and ranking system\n",
    "- Interactive matching interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded. BERT: True, Flask: True\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Optional, Union\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Natural Language Processing\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# BERT and Transformers\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    import torch\n",
    "    BERT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    BERT_AVAILABLE = False\n",
    "\n",
    "# Web Framework\n",
    "try:\n",
    "    from flask import Flask, request, jsonify\n",
    "    from flask_cors import CORS\n",
    "    FLASK_AVAILABLE = True\n",
    "except ImportError:\n",
    "    FLASK_AVAILABLE = False\n",
    "\n",
    "# Additional utilities\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Download NLTK data\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"Libraries loaded. BERT: {BERT_AVAILABLE}, Flask: {FLASK_AVAILABLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure optional flags exist\n",
    "try:\n",
    "    DATABASE_AVAILABLE\n",
    "except NameError:\n",
    "    DATABASE_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Job Posts Dataset: (19001, 24)\n",
      "Resume Dataset: (2484, 4)\n",
      "Cleaned Dataset: (32481, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "print(\"Loading datasets...\")\n",
    "df_jobs = pd.read_csv('Dataset/data job posts.csv')\n",
    "df_resumes = pd.read_csv('Dataset/Resume.csv')\n",
    "df_cleaned = pd.read_csv('Dataset/updated_data_final_cleaned.csv')\n",
    "\n",
    "print(f\"Job Posts Dataset: {df_jobs.shape}\")\n",
    "print(f\"Resume Dataset: {df_resumes.shape}\")\n",
    "print(f\"Cleaned Dataset: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Posts: (19001, 24)\n",
      "Columns: ['jobpost', 'date', 'Title', 'Company', 'AnnouncementCode', 'Term', 'Eligibility', 'Audience', 'StartDate', 'Duration', 'Location', 'JobDescription', 'JobRequirment', 'RequiredQual', 'Salary', 'ApplicationP', 'OpeningDate', 'Deadline', 'Notes', 'AboutC', 'Attach', 'Year', 'Month', 'IT']\n",
      "Missing values: 137017\n",
      "\n",
      "Sample data:\n",
      "                                                      Title  \\\n",
      "0                                   Chief Financial Officer   \n",
      "1  Full-time Community Connections Intern (paid internship)   \n",
      "2                                       Country Coordinator   \n",
      "\n",
      "                                           Company  \\\n",
      "0             AMERIA Investment Consulting Company   \n",
      "1  International Research & Exchanges Board (IREX)   \n",
      "2        Caucasus Environmental NGO Network (CENN)   \n",
      "\n",
      "                                                                                              Location  \n",
      "0                                                                                     Yerevan, Armenia  \n",
      "1  IREX Armenia Main Office; Yerevan, Armenia \\r\\nDESCRIPTION:   IREX currently seeks to fill the p...  \n",
      "2                                                                                     Yerevan, Armenia  \n"
     ]
    }
   ],
   "source": [
    "# Explore job posts dataset\n",
    "if df_jobs is not None:\n",
    "    print(f\"Job Posts: {df_jobs.shape}\")\n",
    "    print(f\"Columns: {list(df_jobs.columns)}\")\n",
    "    print(f\"Missing values: {df_jobs.isnull().sum().sum()}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    print(df_jobs[['Title', 'Company', 'Location']].head(3))\n",
    "else:\n",
    "    print(\"No job data loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESUME DATASET ===\n",
      "Shape: (2484, 4)\n",
      "\n",
      "Columns: ['ID', 'Resume_str', 'Resume_html', 'Category']\n",
      "\n",
      "Missing values:\n",
      "ID             0\n",
      "Resume_str     0\n",
      "Resume_html    0\n",
      "Category       0\n",
      "dtype: int64\n",
      "\n",
      "Resume categories:\n",
      "Category\n",
      "INFORMATION-TECHNOLOGY    120\n",
      "BUSINESS-DEVELOPMENT      120\n",
      "FINANCE                   118\n",
      "ADVOCATE                  118\n",
      "ACCOUNTANT                118\n",
      "ENGINEERING               118\n",
      "CHEF                      118\n",
      "AVIATION                  117\n",
      "FITNESS                   117\n",
      "SALES                     116\n",
      "BANKING                   115\n",
      "HEALTHCARE                115\n",
      "CONSULTANT                115\n",
      "CONSTRUCTION              112\n",
      "PUBLIC-RELATIONS          111\n",
      "HR                        110\n",
      "DESIGNER                  107\n",
      "ARTS                      103\n",
      "TEACHER                   102\n",
      "APPAREL                    97\n",
      "DIGITAL-MEDIA              96\n",
      "AGRICULTURE                63\n",
      "AUTOMOBILE                 36\n",
      "BPO                        22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Cu...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS       Summary     Versatile  media professional with ba...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 20 years experience in recruiting,   15 plus years ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"&gt; &lt;div class=...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  \\\n",
       "0  16852973   \n",
       "1  22323967   \n",
       "2  33176873   \n",
       "\n",
       "                                                                                            Resume_str  \\\n",
       "0           HR ADMINISTRATOR/MARKETING ASSOCIATE\\n\\nHR ADMINISTRATOR       Summary     Dedicated Cu...   \n",
       "1           HR SPECIALIST, US HR OPERATIONS       Summary     Versatile  media professional with ba...   \n",
       "2           HR DIRECTOR       Summary      Over 20 years experience in recruiting,   15 plus years ...   \n",
       "\n",
       "                                                                                           Resume_html  \\\n",
       "0  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "1  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "2  <div class=\"fontsize fontface vmargins hmargins linespacing pagesize\" id=\"document\"> <div class=...   \n",
       "\n",
       "  Category  \n",
       "0       HR  \n",
       "1       HR  \n",
       "2       HR  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore resume dataset\n",
    "print(\"=== RESUME DATASET ===\")\n",
    "print(f\"Shape: {df_resumes.shape}\")\n",
    "print(f\"\\nColumns: {list(df_resumes.columns)}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df_resumes.isnull().sum())\n",
    "print(f\"\\nResume categories:\")\n",
    "print(df_resumes['Category'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_resumes.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model loaded successfully\")\n",
    "except OSError:\n",
    "    print(\"spaCy model not found. Please install it using: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BERT models loaded on cpu\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT models\n",
    "if BERT_AVAILABLE:\n",
    "    try:\n",
    "        bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "        bert_model_direct = AutoModel.from_pretrained('bert-base-uncased')\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        bert_model_direct.to(device)\n",
    "        print(f\"‚úÖ BERT models loaded on {device}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BERT loading failed: {e}\")\n",
    "        bert_model = bert_tokenizer = bert_model_direct = None\n",
    "else:\n",
    "    bert_model = bert_tokenizer = bert_model_direct = None\n",
    "\n",
    "# BERT Functions\n",
    "def get_bert_embeddings(texts, model_type='sentence_transformer'):\n",
    "    \"\"\"Get BERT embeddings for texts\"\"\"\n",
    "    if not BERT_AVAILABLE or not texts:\n",
    "        return np.array([])\n",
    "    \n",
    "    try:\n",
    "        if model_type == 'sentence_transformer' and bert_model:\n",
    "            return bert_model.encode(texts, convert_to_tensor=False)\n",
    "        return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"BERT embedding error: {e}\")\n",
    "        return np.array([])\n",
    "\n",
    "def calculate_bert_similarity(text1, text2):\n",
    "    \"\"\"Calculate semantic similarity between two texts\"\"\"\n",
    "    if not BERT_AVAILABLE or not bert_model:\n",
    "        return 0.0\n",
    "    \n",
    "    try:\n",
    "        embeddings = bert_model.encode([text1, text2])\n",
    "        return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def extract_skills_bert(text, threshold=0.7):\n",
    "    \"\"\"Extract skills from text using BERT\"\"\"\n",
    "    if not BERT_AVAILABLE or not text:\n",
    "        return []\n",
    "    \n",
    "    skill_keywords = [\n",
    "        'python', 'java', 'javascript', 'react', 'angular', 'vue', 'node.js',\n",
    "        'machine learning', 'deep learning', 'artificial intelligence', 'ai',\n",
    "        'data science', 'data analysis', 'statistics', 'sql', 'database',\n",
    "        'aws', 'azure', 'docker', 'kubernetes', 'git', 'github',\n",
    "        'project management', 'agile', 'scrum', 'leadership', 'communication',\n",
    "        'marketing', 'sales', 'finance', 'accounting', 'human resources',\n",
    "        'design', 'ui', 'ux', 'photoshop', 'illustrator', 'figma',\n",
    "        'mobile development', 'ios', 'android', 'swift', 'kotlin',\n",
    "        'web development', 'frontend', 'backend', 'full stack', 'devops'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        extracted_skills = []\n",
    "        text_lower = text.lower()\n",
    "        \n",
    "        for skill in skill_keywords:\n",
    "            similarity = calculate_bert_similarity(text_lower, skill)\n",
    "            if similarity >= threshold:\n",
    "                extracted_skills.append(skill)\n",
    "        \n",
    "        return list(set(extracted_skills))\n",
    "    except Exception as e:\n",
    "        print(f\"BERT skill extraction error: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Cache directory: /Users/sadmanrahin/Documents/btt_AI/cache\n",
      "   Jobs cache: False\n",
      "   Resumes cache: False\n"
     ]
    }
   ],
   "source": [
    "# Setup caching system\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "CACHE_JOBS = CACHE_DIR / \"df_jobs_clean.pkl\"\n",
    "CACHE_RESUMES = CACHE_DIR / \"df_resumes_clean.pkl\"\n",
    "\n",
    "print(f\"üì¶ Cache directory: {CACHE_DIR.absolute()}\")\n",
    "print(f\"   Jobs cache: {CACHE_JOBS.exists()}\")\n",
    "print(f\"   Resumes cache: {CACHE_RESUMES.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Matching Functions\n",
    "def find_best_matches_bert(job_index, df_jobs, df_resumes, top_n=5):\n",
    "    \"\"\"Find best matching resumes using BERT\"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job_text = df_jobs.iloc[job_index]['CleanText']\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        \n",
    "        job_embedding = bert_model.encode([job_text])\n",
    "        resume_embeddings = bert_model.encode(resume_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': df_resumes.iloc[idx]['ID'],\n",
    "                'Category': df_resumes.iloc[idx]['Category'],\n",
    "                'BERT_Similarity_Score': similarities[idx],  # Fixed column name\n",
    "                'Resume_Text': df_resumes.iloc[idx]['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def enhanced_matching_bert(job_index, df_jobs, df_resumes, top_n=5, skill_weight=0.3, bert_weight=0.7):\n",
    "    \"\"\"Enhanced matching using BERT + skill overlap\"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        job = df_jobs.iloc[job_index]\n",
    "        job_text = job['CleanText']\n",
    "        job_skills = set(job['Skills']) if job['Skills'] else set()\n",
    "        \n",
    "        job_embedding = bert_model.encode([job_text])\n",
    "        resume_texts = df_resumes['CleanText'].tolist()\n",
    "        resume_embeddings = bert_model.encode(resume_texts)\n",
    "        \n",
    "        bert_similarities = cosine_similarity(job_embedding, resume_embeddings).flatten()\n",
    "        \n",
    "        skill_scores = []\n",
    "        for idx, resume in df_resumes.iterrows():\n",
    "            resume_skills = set(resume['Skills']) if resume['Skills'] else set()\n",
    "            \n",
    "            if job_skills and resume_skills:\n",
    "                overlap = len(job_skills.intersection(resume_skills))\n",
    "                skill_score = overlap / len(job_skills) if job_skills else 0\n",
    "            else:\n",
    "                skill_score = 0\n",
    "            \n",
    "            skill_scores.append(skill_score)\n",
    "        \n",
    "        combined_scores = bert_weight * bert_similarities + skill_weight * np.array(skill_scores)\n",
    "        top_indices = combined_scores.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            resume = df_resumes.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': resume['ID'],\n",
    "                'Category': resume['Category'],\n",
    "                'BERT_Similarity_Score': bert_similarities[idx],  # Fixed column name\n",
    "                'Skill_Overlap_Score': skill_scores[idx],\n",
    "                'Combined_Score': combined_scores[idx],\n",
    "                'Resume_Text': resume['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"Enhanced BERT matching error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def search_jobs_by_keywords_bert(keywords, df_jobs, top_n=5):\n",
    "    \"\"\"Search for jobs by keywords using BERT\"\"\"\n",
    "    if not BERT_AVAILABLE or bert_model is None:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        clean_keywords = clean_text(keywords)\n",
    "        keyword_embedding = bert_model.encode([clean_keywords])\n",
    "        job_texts = df_jobs['CleanText'].tolist()\n",
    "        job_embeddings = bert_model.encode(job_texts)\n",
    "        \n",
    "        similarities = cosine_similarity(keyword_embedding, job_embeddings).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            job = df_jobs.iloc[idx]\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Title': job['Title'],\n",
    "                'Company': job['Company'],\n",
    "                'Location': job['Location'],\n",
    "                'BERT_Similarity_Score': similarities[idx],  # Fixed column name\n",
    "                'Description': job['JobDescription'][:200] + '...' if pd.notna(job['JobDescription']) else 'N/A'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"BERT job search error: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing functions\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<.*?>', ' ', text)  # Remove HTML\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)  # Remove special chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Clean whitespace\n",
    "    return text\n",
    "\n",
    "def extract_skills(text, nlp_model):\n",
    "    \"\"\"Extract skills from text\"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return []\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    skills = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if (token.pos_ in ['NOUN', 'PROPN'] and \n",
    "            not token.is_stop and \n",
    "            len(token.text) > 2 and\n",
    "            token.text.isalpha()):\n",
    "            skills.append(token.lemma_.lower())\n",
    "    \n",
    "    return list(set(skills))\n",
    "\n",
    "def lemmatize_text(text, nlp_model):\n",
    "    \"\"\"Lemmatize text for better matching\"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n",
    "\n",
    "# TF-IDF matching function\n",
    "def find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes, top_n=5):\n",
    "    \"\"\"Find best matching resumes using TF-IDF\"\"\"\n",
    "    try:\n",
    "        job_vector = job_tfidf[job_index]\n",
    "        similarities = cosine_similarity(job_vector, resume_tfidf).flatten()\n",
    "        top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'Rank': i + 1,\n",
    "                'Resume_ID': df_resumes.iloc[idx]['ID'],\n",
    "                'Category': df_resumes.iloc[idx]['Category'],\n",
    "                'Similarity_Score': similarities[idx],\n",
    "                'Resume_Text': df_resumes.iloc[idx]['Resume_str'][:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        print(f\"TF-IDF matching error: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading preprocessed data from cache...\n",
      "‚úÖ Loaded from cache: 822 jobs, 2484 resumes\n",
      "üí° To reprocess, delete cache/ folder or the .pkl files\n",
      "‚úÖ Using cached preprocessed data\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing with caching\n",
    "if CACHE_JOBS.exists() and CACHE_RESUMES.exists():\n",
    "    print(\"üì¶ Loading preprocessed data from cache...\")\n",
    "    try:\n",
    "        df_jobs_clean = pd.read_pickle(CACHE_JOBS)\n",
    "        df_resumes_clean = pd.read_pickle(CACHE_RESUMES)\n",
    "        print(f\"‚úÖ Loaded from cache: {len(df_jobs_clean)} jobs, {len(df_resumes_clean)} resumes\")\n",
    "        print(\"üí° To reprocess, delete cache/ folder or the .pkl files\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading cache: {e}\")\n",
    "        print(\"üîÑ Reprocessing data...\")\n",
    "        cache_available = False\n",
    "    else:\n",
    "        cache_available = True\n",
    "else:\n",
    "    cache_available = False\n",
    "    print(\"üì¶ No cache found. Processing data...\")\n",
    "\n",
    "# Process data if cache not available\n",
    "if not cache_available and df_jobs is not None and df_resumes is not None:\n",
    "    # Use subset for testing (remove this line for full processing)\n",
    "    df_jobs_subset = df_jobs.head(1000)  # Process only first 1000 jobs\n",
    "    df_resumes_subset = df_resumes.head(5000)  # Process only first 5000 resumes\n",
    "    \n",
    "    print(f\"Processing subset: {len(df_jobs_subset)} jobs, {len(df_resumes_subset)} resumes\")\n",
    "    \n",
    "    # Clean job posts\n",
    "    job_columns = ['Title', 'Company', 'Location', 'JobDescription', 'JobRequirment', 'RequiredQual']\n",
    "    df_jobs_clean = df_jobs_subset[job_columns].copy()\n",
    "    df_jobs_clean = df_jobs_clean.dropna(subset=['Title', 'JobDescription'])\n",
    "    df_jobs_clean = df_jobs_clean.reset_index(drop=True)\n",
    "    \n",
    "    # Create combined text\n",
    "    df_jobs_clean['CombinedText'] = (\n",
    "        df_jobs_clean['Title'].fillna('') + ' ' +\n",
    "        df_jobs_clean['JobDescription'].fillna('') + ' ' +\n",
    "        df_jobs_clean['JobRequirment'].fillna('') + ' ' +\n",
    "        df_jobs_clean['RequiredQual'].fillna('')\n",
    "    )\n",
    "    \n",
    "    # Clean text\n",
    "    print(\"Cleaning job text...\")\n",
    "    df_jobs_clean['CleanText'] = df_jobs_clean['CombinedText'].apply(clean_text)\n",
    "    \n",
    "    # Extract skills\n",
    "    if nlp:\n",
    "        print(\"Extracting job skills...\")\n",
    "        df_jobs_clean['Skills'] = df_jobs_clean['CleanText'].apply(lambda x: extract_skills(x, nlp))\n",
    "        df_jobs_clean['LemmatizedText'] = df_jobs_clean['CleanText'].apply(lambda x: lemmatize_text(x, nlp))\n",
    "    else:\n",
    "        df_jobs_clean['Skills'] = [[] for _ in range(len(df_jobs_clean))]\n",
    "        df_jobs_clean['LemmatizedText'] = df_jobs_clean['CleanText']\n",
    "    \n",
    "    # Clean resumes\n",
    "    df_resumes_clean = df_resumes_subset.copy()\n",
    "    print(\"Cleaning resume text...\")\n",
    "    df_resumes_clean['CleanText'] = df_resumes_clean['Resume_str'].apply(clean_text)\n",
    "    \n",
    "    if nlp:\n",
    "        print(\"Extracting resume skills...\")\n",
    "        df_resumes_clean['Skills'] = df_resumes_clean['CleanText'].apply(lambda x: extract_skills(x, nlp))\n",
    "        df_resumes_clean['LemmatizedText'] = df_resumes_clean['CleanText'].apply(lambda x: lemmatize_text(x, nlp))\n",
    "    else:\n",
    "        df_resumes_clean['Skills'] = [[] for _ in range(len(df_resumes_clean))]\n",
    "        df_resumes_clean['LemmatizedText'] = df_resumes_clean['CleanText']\n",
    "    \n",
    "    # Save to cache\n",
    "    print(\"üíæ Saving preprocessed data to cache...\")\n",
    "    df_jobs_clean.to_pickle(CACHE_JOBS)\n",
    "    df_resumes_clean.to_pickle(CACHE_RESUMES)\n",
    "    print(f\"‚úÖ Saved to cache: {len(df_jobs_clean)} jobs, {len(df_resumes_clean)} resumes\")\n",
    "    \n",
    "elif cache_available:\n",
    "    print(\"‚úÖ Using cached preprocessed data\")\n",
    "elif df_jobs is None or df_resumes is None:\n",
    "    print(\"‚ùå No data to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF vectors...\n",
      "‚úÖ TF-IDF matrix created: (3306, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create TF-IDF vectors\n",
    "if 'df_jobs_clean' in locals() and 'df_resumes_clean' in locals():\n",
    "    print(\"Creating TF-IDF vectors...\")\n",
    "    \n",
    "    # Combine all text for vocabulary\n",
    "    all_texts = list(df_jobs_clean['LemmatizedText']) + list(df_resumes_clean['LemmatizedText'])\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.8\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Split back into job posts and resumes\n",
    "    n_jobs = len(df_jobs_clean)\n",
    "    job_tfidf = tfidf_matrix[:n_jobs]\n",
    "    resume_tfidf = tfidf_matrix[n_jobs:]\n",
    "    \n",
    "    print(f\"‚úÖ TF-IDF matrix created: {tfidf_matrix.shape}\")\n",
    "else:\n",
    "    print(\"‚ùå Cleaned data not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing BERT vs TF-IDF performance...\n",
      "üöÄ Running BERT integration tests...\n",
      "üîç Comparing matching methods for job: Chief Financial Officer\n",
      "================================================================================\n",
      "üìä Testing TF-IDF method...\n",
      "‚úÖ TF-IDF method completed\n",
      "\n",
      "üß† Testing BERT method...\n",
      "‚úÖ BERT method completed\n",
      "\n",
      "üöÄ Testing Enhanced BERT method...\n",
      "‚úÖ Enhanced BERT method completed\n",
      "\n",
      "üìã RESULTS COMPARISON:\n",
      "================================================================================\n",
      "\n",
      "üî§ TF-IDF Results:\n",
      " Rank  Resume_ID Category  Similarity_Score\n",
      "    1   12071138  FINANCE          0.438454\n",
      "    2   19234823 ADVOCATE          0.431891\n",
      "    3   18636651  FINANCE          0.426520\n",
      "    4   17392859  FINANCE          0.401932\n",
      "    5   84356308  FINANCE          0.398916\n",
      "\n",
      "üß† BERT Results:\n",
      " Rank  Resume_ID Category  BERT_Similarity_Score\n",
      "    1   17392859  FINANCE               0.752344\n",
      "    2   15891494  FINANCE               0.743289\n",
      "    3   14722634  FINANCE               0.737250\n",
      "    4   26767199  FINANCE               0.730880\n",
      "    5   38441665  FINANCE               0.723948\n",
      "\n",
      "üöÄ Enhanced BERT Results:\n",
      " Rank  Resume_ID Category  BERT_Similarity_Score  Skill_Overlap_Score  Combined_Score\n",
      "    1   14722634  FINANCE               0.737250             0.423611        0.643159\n",
      "    2   19234823 ADVOCATE               0.721044             0.451389        0.640147\n",
      "    3   17392859  FINANCE               0.752344             0.368056        0.637057\n",
      "    4   15891494  FINANCE               0.743289             0.381944        0.634886\n",
      "    5   81677620  FINANCE               0.715356             0.395833        0.619499\n",
      "üîç Comparing skill extraction methods...\n",
      "============================================================\n",
      "‚ùå Cleaned job data not available\n",
      "\n",
      "‚úÖ BERT integration testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test BERT vs TF-IDF Performance Comparison\n",
    "print(\"üß™ Testing BERT vs TF-IDF performance...\")\n",
    "\n",
    "def compare_matching_methods(job_index=0, top_n=5):\n",
    "    \"\"\"Compare BERT and TF-IDF matching methods\"\"\"\n",
    "    if df_jobs is None or df_resumes is None:\n",
    "        print(\"‚ùå Datasets not loaded. Please run the data loading cell first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîç Comparing matching methods for job: {df_jobs.iloc[job_index]['Title']}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Test TF-IDF method (original)\n",
    "    print(\"üìä Testing TF-IDF method...\")\n",
    "    try:\n",
    "        tfidf_matches = find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes_clean, top_n)\n",
    "        print(\"‚úÖ TF-IDF method completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå TF-IDF method failed: {str(e)}\")\n",
    "        tfidf_matches = pd.DataFrame()\n",
    "    \n",
    "    # Test BERT method\n",
    "    print(\"\\nüß† Testing BERT method...\")\n",
    "    try:\n",
    "        bert_matches = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "        print(\"‚úÖ BERT method completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BERT method failed: {str(e)}\")\n",
    "        bert_matches = pd.DataFrame()\n",
    "    \n",
    "    # Test Enhanced BERT method\n",
    "    print(\"\\nüöÄ Testing Enhanced BERT method...\")\n",
    "    try:\n",
    "        enhanced_bert_matches = enhanced_matching_bert(job_index, df_jobs_clean, df_resumes_clean, top_n)\n",
    "        print(\"‚úÖ Enhanced BERT method completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Enhanced BERT method failed: {str(e)}\")\n",
    "        enhanced_bert_matches = pd.DataFrame()\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìã RESULTS COMPARISON:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not tfidf_matches.empty:\n",
    "        print(\"\\nüî§ TF-IDF Results:\")\n",
    "        print(tfidf_matches[['Rank', 'Resume_ID', 'Category', 'Similarity_Score']].to_string(index=False))\n",
    "    \n",
    "    if not bert_matches.empty:\n",
    "        print(\"\\nüß† BERT Results:\")\n",
    "        print(bert_matches[['Rank', 'Resume_ID', 'Category', 'BERT_Similarity_Score']].to_string(index=False))\n",
    "    \n",
    "    if not enhanced_bert_matches.empty:\n",
    "        print(\"\\nüöÄ Enhanced BERT Results:\")\n",
    "        print(enhanced_bert_matches[['Rank', 'Resume_ID', 'Category', 'BERT_Similarity_Score', 'Skill_Overlap_Score', 'Combined_Score']].to_string(index=False))\n",
    "    \n",
    "    return {\n",
    "        'tfidf_matches': tfidf_matches,\n",
    "        'bert_matches': bert_matches,\n",
    "        'enhanced_bert_matches': enhanced_bert_matches\n",
    "    }\n",
    "\n",
    "def test_skill_extraction_comparison():\n",
    "    \"\"\"Compare skill extraction between spaCy and BERT methods\"\"\"\n",
    "    if df_jobs is None or not BERT_AVAILABLE:\n",
    "        print(\"‚ùå Datasets not loaded or BERT not available.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üîç Comparing skill extraction methods...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test on a sample job from cleaned data\n",
    "    if 'df_jobs_clean' in globals() and len(globals()['df_jobs_clean']) > 0:\n",
    "        sample_job = df_jobs_clean.iloc[0]\n",
    "        job_text = sample_job['CleanText']\n",
    "        \n",
    "        print(f\"üìã Sample Job: {sample_job['Title']}\")\n",
    "        print(f\"üìù Job Text: {job_text[:200]}...\")\n",
    "        \n",
    "        # spaCy skill extraction\n",
    "        if nlp:\n",
    "            spacy_skills = extract_skills(job_text, nlp)\n",
    "            print(f\"\\nüî§ spaCy Skills ({len(spacy_skills)}): {spacy_skills[:10]}\")\n",
    "        \n",
    "        # BERT skill extraction\n",
    "        bert_skills = extract_skills_bert(job_text)\n",
    "        print(f\"\\nüß† BERT Skills ({len(bert_skills)}): {bert_skills}\")\n",
    "        \n",
    "        # Compare\n",
    "        if nlp and spacy_skills:\n",
    "            spacy_set = set(spacy_skills)\n",
    "            bert_set = set(bert_skills)\n",
    "            overlap = len(spacy_set.intersection(bert_set))\n",
    "            union = len(spacy_set.union(bert_set))\n",
    "            \n",
    "            print(f\"\\nüìä Skill Extraction Comparison:\")\n",
    "            print(f\"   spaCy skills: {len(spacy_skills)}\")\n",
    "            print(f\"   BERT skills: {len(bert_skills)}\")\n",
    "            print(f\"   Overlap: {overlap}\")\n",
    "            print(f\"   Jaccard similarity: {overlap/union:.3f}\")\n",
    "    else:\n",
    "        print(\"‚ùå Cleaned job data not available\")\n",
    "\n",
    "# Run comparison tests\n",
    "print(\"üöÄ Running BERT integration tests...\")\n",
    "\n",
    "# Test matching methods\n",
    "comparison_results = compare_matching_methods(job_index=0, top_n=5)\n",
    "\n",
    "# Test skill extraction\n",
    "test_skill_extraction_comparison()\n",
    "\n",
    "print(\"\\n‚úÖ BERT integration testing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing system...\n",
      "BERT similarity test: 0.494\n",
      "Skills extracted: ['machine', 'learning', 'python']\n",
      "‚úÖ System test completed\n"
     ]
    }
   ],
   "source": [
    "# Test the system\n",
    "print(\"üß™ Testing system...\")\n",
    "\n",
    "# Test BERT similarity\n",
    "if BERT_AVAILABLE:\n",
    "    similarity = calculate_bert_similarity(\"python developer\", \"software engineer\")\n",
    "    print(f\"BERT similarity test: {similarity:.3f}\")\n",
    "\n",
    "# Test skill extraction\n",
    "if nlp:\n",
    "    skills = extract_skills(\"I know Python and machine learning\", nlp)\n",
    "    print(f\"Skills extracted: {skills}\")\n",
    "\n",
    "print(\"‚úÖ System test completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Simple comparison test...\n",
      "‚úÖ TF-IDF: Found 3 matches\n",
      "Top TF-IDF match: 12071138\n",
      "‚úÖ BERT: Found 3 matches\n",
      "Top BERT match: 17392859\n",
      "Available columns: ['Rank', 'Resume_ID', 'Category', 'BERT_Similarity_Score', 'Resume_Text']\n",
      "‚úÖ Test completed\n"
     ]
    }
   ],
   "source": [
    "# Simple comparison test\n",
    "def simple_test():\n",
    "    \"\"\"Simple test that works with any column names\"\"\"\n",
    "    if df_jobs is None or df_resumes is None:\n",
    "        print(\"‚ùå Datasets not loaded\")\n",
    "        return\n",
    "    \n",
    "    print(\"üß™ Simple comparison test...\")\n",
    "    \n",
    "    # Test TF-IDF\n",
    "    try:\n",
    "        tfidf_results = find_best_matches(0, resume_tfidf, job_tfidf, df_resumes_clean, 3)\n",
    "        print(f\"‚úÖ TF-IDF: Found {len(tfidf_results)} matches\")\n",
    "        if not tfidf_results.empty:\n",
    "            print(\"Top TF-IDF match:\", tfidf_results.iloc[0]['Resume_ID'])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå TF-IDF error: {e}\")\n",
    "    \n",
    "    # Test BERT\n",
    "    try:\n",
    "        bert_results = find_best_matches_bert(0, df_jobs_clean, df_resumes_clean, 3)\n",
    "        print(f\"‚úÖ BERT: Found {len(bert_results)} matches\")\n",
    "        if not bert_results.empty:\n",
    "            print(\"Top BERT match:\", bert_results.iloc[0]['Resume_ID'])\n",
    "            print(\"Available columns:\", list(bert_results.columns))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BERT error: {e}\")\n",
    "    \n",
    "    print(\"‚úÖ Test completed\")\n",
    "\n",
    "# Run the test\n",
    "simple_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking data availability...\n",
      "df_jobs: ‚úÖ Available\n",
      "df_resumes: ‚úÖ Available\n",
      "df_jobs_clean: ‚úÖ Available\n",
      "df_resumes_clean: ‚úÖ Available\n",
      "job_tfidf: ‚úÖ Available\n",
      "resume_tfidf: ‚úÖ Available\n",
      "\n",
      "Original data shapes:\n",
      "  Jobs: (19001, 24)\n",
      "  Resumes: (2484, 4)\n",
      "\n",
      "Cleaned data shapes:\n",
      "  Jobs: (822, 10)\n",
      "  Resumes: (2484, 7)\n",
      "\n",
      "üí° If cleaned data is not available, run the data preprocessing cell (Cell 9) first!\n"
     ]
    }
   ],
   "source": [
    "# Check data availability\n",
    "print(\"üîç Checking data availability...\")\n",
    "\n",
    "print(f\"df_jobs: {'‚úÖ Available' if 'df_jobs' in locals() and df_jobs is not None else '‚ùå Not available'}\")\n",
    "print(f\"df_resumes: {'‚úÖ Available' if 'df_resumes' in locals() and df_resumes is not None else '‚ùå Not available'}\")\n",
    "print(f\"df_jobs_clean: {'‚úÖ Available' if 'df_jobs_clean' in locals() else '‚ùå Not available'}\")\n",
    "print(f\"df_resumes_clean: {'‚úÖ Available' if 'df_resumes_clean' in locals() else '‚ùå Not available'}\")\n",
    "print(f\"job_tfidf: {'‚úÖ Available' if 'job_tfidf' in locals() else '‚ùå Not available'}\")\n",
    "print(f\"resume_tfidf: {'‚úÖ Available' if 'resume_tfidf' in locals() else '‚ùå Not available'}\")\n",
    "\n",
    "if 'df_jobs' in locals() and df_jobs is not None:\n",
    "    print(f\"\\nOriginal data shapes:\")\n",
    "    print(f\"  Jobs: {df_jobs.shape}\")\n",
    "    print(f\"  Resumes: {df_resumes.shape if 'df_resumes' in locals() and df_resumes is not None else 'N/A'}\")\n",
    "\n",
    "if 'df_jobs_clean' in locals():\n",
    "    print(f\"\\nCleaned data shapes:\")\n",
    "    print(f\"  Jobs: {df_jobs_clean.shape}\")\n",
    "    print(f\"  Resumes: {df_resumes_clean.shape if 'df_resumes_clean' in locals() else 'N/A'}\")\n",
    "\n",
    "print(\"\\nüí° If cleaned data is not available, run the data preprocessing cell (Cell 9) first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ BERT Integration Demo\n",
      "==================================================\n",
      "üöÄ Welcome to the Enhanced AI Recruitment System with BERT!\n",
      "\n",
      "üìã Available Features:\n",
      "1. üß† BERT-based semantic matching\n",
      "2. üîç Enhanced skill extraction\n",
      "3. üìä Performance comparison (BERT vs TF-IDF)\n",
      "4. üéØ Improved job-resume matching accuracy\n",
      "\n",
      "‚úÖ BERT Status: Available\n",
      "üñ•Ô∏è Device: cpu\n",
      "\n",
      "üß™ Demo: BERT Semantic Similarity\n",
      "----------------------------------------\n",
      "'machine learning engineer' ‚Üî 'data scientist': 0.608\n",
      "'python developer' ‚Üî 'software engineer': 0.494\n",
      "'project manager' ‚Üî 'team lead': 0.309\n",
      "'marketing specialist' ‚Üî 'sales representative': 0.598\n",
      "\n",
      "üîç Demo: BERT Skill Extraction\n",
      "----------------------------------------\n",
      "Text: I have experience with Python, machine learning, AWS, and project management using agile methodologies.\n",
      "Extracted skills: []\n",
      "\n",
      "üìñ USAGE GUIDE\n",
      "==================================================\n",
      "\n",
      "üîß How to use BERT features:\n",
      "1. Load your datasets using the data loading cell\n",
      "2. Initialize BERT models using the BERT initialization cell\n",
      "3. Use the following functions:\n",
      "\n",
      "üìã Available Functions:\n",
      "‚Ä¢ find_best_matches_bert() - BERT-based resume matching\n",
      "‚Ä¢ enhanced_matching_bert() - BERT + skill overlap matching\n",
      "‚Ä¢ search_jobs_by_keywords_bert() - BERT-based job search\n",
      "‚Ä¢ extract_skills_bert() - BERT-based skill extraction\n",
      "‚Ä¢ calculate_bert_similarity() - Semantic similarity between texts\n",
      "‚Ä¢ compare_matching_methods() - Compare BERT vs TF-IDF\n",
      "\n",
      "üí° Example Usage:\n",
      "```python\n",
      "# Find best resumes for a job using BERT\n",
      "bert_matches = find_best_matches_bert(job_index=0, df_jobs_clean, df_resumes_clean)\n",
      "\n",
      "# Search jobs using semantic understanding\n",
      "job_results = search_jobs_by_keywords_bert('machine learning python', df_jobs_clean)\n",
      "\n",
      "# Extract skills using BERT\n",
      "skills = extract_skills_bert('I know Python and machine learning')\n",
      "```\n",
      "\n",
      "‚ö° Performance Tips:\n",
      "‚Ä¢ BERT is slower than TF-IDF but more accurate\n",
      "‚Ä¢ Use batch processing for large datasets\n",
      "‚Ä¢ Consider using GPU for faster processing\n",
      "‚Ä¢ Adjust similarity thresholds based on your needs\n",
      "\n",
      "üìä SYSTEM STATUS\n",
      "==================================================\n",
      "üì¶ Datasets loaded: ‚úÖ\n",
      "üß† BERT available: ‚úÖ\n",
      "üî§ spaCy available: ‚úÖ\n",
      "üåê Flask available: ‚úÖ\n",
      "üóÑÔ∏è Database available: ‚ùå\n",
      "\n",
      "üìà Dataset Statistics:\n",
      "   Job posts: 19,001\n",
      "   Resumes: 2,484\n",
      "   Resume categories: 24\n",
      "\n",
      "üéØ Matching Methods Available:\n",
      "   TF-IDF + Cosine Similarity: ‚úÖ\n",
      "   BERT Semantic Matching: ‚úÖ\n",
      "   Enhanced BERT + Skills: ‚úÖ\n",
      "\n",
      "üéâ BERT Integration Complete!\n",
      "Your AI recruitment system now has advanced semantic understanding capabilities!\n"
     ]
    }
   ],
   "source": [
    "# BERT Integration Demo and Usage Guide\n",
    "print(\"üéØ BERT Integration Demo\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def demo_bert_features():\n",
    "    \"\"\"\n",
    "    Demonstrate the new BERT features in the recruitment system\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Welcome to the Enhanced AI Recruitment System with BERT!\")\n",
    "    print(\"\\nüìã Available Features:\")\n",
    "    print(\"1. üß† BERT-based semantic matching\")\n",
    "    print(\"2. üîç Enhanced skill extraction\")\n",
    "    print(\"3. üìä Performance comparison (BERT vs TF-IDF)\")\n",
    "    print(\"4. üéØ Improved job-resume matching accuracy\")\n",
    "    \n",
    "    if not BERT_AVAILABLE:\n",
    "        print(\"\\n‚ùå BERT is not available. Please install transformers and torch.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n‚úÖ BERT Status: Available\")\n",
    "    print(f\"üñ•Ô∏è Device: {device if 'device' in globals() else 'CPU'}\")\n",
    "    \n",
    "    # Demo BERT similarity calculation\n",
    "    print(\"\\nüß™ Demo: BERT Semantic Similarity\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    test_pairs = [\n",
    "        (\"machine learning engineer\", \"data scientist\"),\n",
    "        (\"python developer\", \"software engineer\"),\n",
    "        (\"project manager\", \"team lead\"),\n",
    "        (\"marketing specialist\", \"sales representative\")\n",
    "    ]\n",
    "    \n",
    "    for text1, text2 in test_pairs:\n",
    "        similarity = calculate_bert_similarity(text1, text2)\n",
    "        print(f\"'{text1}' ‚Üî '{text2}': {similarity:.3f}\")\n",
    "    \n",
    "    # Demo skill extraction\n",
    "    print(\"\\nüîç Demo: BERT Skill Extraction\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    sample_text = \"I have experience with Python, machine learning, AWS, and project management using agile methodologies.\"\n",
    "    skills = extract_skills_bert(sample_text)\n",
    "    print(f\"Text: {sample_text}\")\n",
    "    print(f\"Extracted skills: {skills}\")\n",
    "\n",
    "def usage_guide():\n",
    "    \"\"\"\n",
    "    Provide usage guide for the new BERT features\n",
    "    \"\"\"\n",
    "    print(\"\\nüìñ USAGE GUIDE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüîß How to use BERT features:\")\n",
    "    print(\"1. Load your datasets using the data loading cell\")\n",
    "    print(\"2. Initialize BERT models using the BERT initialization cell\")\n",
    "    print(\"3. Use the following functions:\")\n",
    "    \n",
    "    print(\"\\nüìã Available Functions:\")\n",
    "    print(\"‚Ä¢ find_best_matches_bert() - BERT-based resume matching\")\n",
    "    print(\"‚Ä¢ enhanced_matching_bert() - BERT + skill overlap matching\")\n",
    "    print(\"‚Ä¢ search_jobs_by_keywords_bert() - BERT-based job search\")\n",
    "    print(\"‚Ä¢ extract_skills_bert() - BERT-based skill extraction\")\n",
    "    print(\"‚Ä¢ calculate_bert_similarity() - Semantic similarity between texts\")\n",
    "    print(\"‚Ä¢ compare_matching_methods() - Compare BERT vs TF-IDF\")\n",
    "    \n",
    "    print(\"\\nüí° Example Usage:\")\n",
    "    print(\"```python\")\n",
    "    print(\"# Find best resumes for a job using BERT\")\n",
    "    print(\"bert_matches = find_best_matches_bert(job_index=0, df_jobs_clean, df_resumes_clean)\")\n",
    "    print(\"\")\n",
    "    print(\"# Search jobs using semantic understanding\")\n",
    "    print(\"job_results = search_jobs_by_keywords_bert('machine learning python', df_jobs_clean)\")\n",
    "    print(\"\")\n",
    "    print(\"# Extract skills using BERT\")\n",
    "    print(\"skills = extract_skills_bert('I know Python and machine learning')\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\n‚ö° Performance Tips:\")\n",
    "    print(\"‚Ä¢ BERT is slower than TF-IDF but more accurate\")\n",
    "    print(\"‚Ä¢ Use batch processing for large datasets\")\n",
    "    print(\"‚Ä¢ Consider using GPU for faster processing\")\n",
    "    print(\"‚Ä¢ Adjust similarity thresholds based on your needs\")\n",
    "\n",
    "def system_status():\n",
    "    \"\"\"\n",
    "    Display current system status and capabilities\n",
    "    \"\"\"\n",
    "    print(\"\\nüìä SYSTEM STATUS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"üì¶ Datasets loaded: {'‚úÖ' if df_jobs is not None and df_resumes is not None else '‚ùå'}\")\n",
    "    print(f\"üß† BERT available: {'‚úÖ' if BERT_AVAILABLE else '‚ùå'}\")\n",
    "    print(f\"üî§ spaCy available: {'‚úÖ' if nlp is not None else '‚ùå'}\")\n",
    "    print(f\"üåê Flask available: {'‚úÖ' if FLASK_AVAILABLE else '‚ùå'}\")\n",
    "    print(f\"üóÑÔ∏è Database available: {'‚úÖ' if DATABASE_AVAILABLE else '‚ùå'}\")\n",
    "    \n",
    "    if df_jobs is not None and df_resumes is not None:\n",
    "        print(f\"\\nüìà Dataset Statistics:\")\n",
    "        print(f\"   Job posts: {len(df_jobs):,}\")\n",
    "        print(f\"   Resumes: {len(df_resumes):,}\")\n",
    "        print(f\"   Resume categories: {df_resumes['Category'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Matching Methods Available:\")\n",
    "    print(f\"   TF-IDF + Cosine Similarity: ‚úÖ\")\n",
    "    print(f\"   BERT Semantic Matching: {'‚úÖ' if BERT_AVAILABLE else '‚ùå'}\")\n",
    "    print(f\"   Enhanced BERT + Skills: {'‚úÖ' if BERT_AVAILABLE else '‚ùå'}\")\n",
    "\n",
    "# Run the demo\n",
    "if __name__ == \"__main__\":\n",
    "    demo_bert_features()\n",
    "    usage_guide()\n",
    "    system_status()\n",
    "    \n",
    "    print(\"\\nüéâ BERT Integration Complete!\")\n",
    "    print(\"Your AI recruitment system now has advanced semantic understanding capabilities!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing functions\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_skills(text, nlp_model):\n",
    "    \"\"\"Extract skills and important keywords from text\"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return []\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    skills = []\n",
    "    \n",
    "    # Extract nouns and proper nouns (potential skills)\n",
    "    for token in doc:\n",
    "        if (token.pos_ in ['NOUN', 'PROPN'] and \n",
    "            not token.is_stop and \n",
    "            len(token.text) > 2 and\n",
    "            token.text.isalpha()):\n",
    "            skills.append(token.lemma_.lower())\n",
    "    \n",
    "    return list(set(skills))\n",
    "\n",
    "def lemmatize_text(text, nlp_model):\n",
    "    \"\"\"Lemmatize text for better matching\"\"\"\n",
    "    if not nlp_model or not text:\n",
    "        return \"\"\n",
    "    \n",
    "    doc = nlp_model(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing job search...\n",
      "\n",
      "Job search results for 'software developer python':\n",
      "   Rank                                          Title  \\\n",
      "0     1                  Software Developer/Programmer   \n",
      "1     2                             Software developer   \n",
      "2     3  Senior Software Developer (several positions)   \n",
      "3     4                             Software Developer   \n",
      "4     5                         Developers Team Leader   \n",
      "\n",
      "                                       Company          Location  \\\n",
      "0                                      IIG LLC  Yerevan, Armenia   \n",
      "1                                     Xalt LLC  Yerevan, Armenia   \n",
      "2                                    ZenteX.AM  Yerevan, Armenia   \n",
      "3  Synergy International Systems, Inc./Armenia  Yerevan, Armenia   \n",
      "4                                    Zenteq.am  Yerevan, Armenia   \n",
      "\n",
      "   Similarity_Score  \\\n",
      "0          0.436298   \n",
      "1          0.419878   \n",
      "2          0.412981   \n",
      "3          0.345645   \n",
      "4          0.313760   \n",
      "\n",
      "                                                                                           Description  \n",
      "0                                                Development of programs for business applications....  \n",
      "1  Xalt LLC is seeking for a motivated and experienced\\r\\nSoftware Developer in Web environment who...  \n",
      "2  ZenteX.AM is seeking software developers to fill\\r\\npositions in its expanding development team....  \n",
      "3  Synergy International Systems, Inc./Armenia seeks to\\r\\nfill the long-term position of Software ...  \n",
      "4  The duties of the Developers Team Leader include\\r\\nplanning and permanent coordination of devel...  \n"
     ]
    }
   ],
   "source": [
    "# Interactive Job Search Function\n",
    "def search_jobs_by_keywords(keywords, df_jobs, job_tfidf, vectorizer, top_n=5):\n",
    "    \"\"\"Search for jobs by keywords\"\"\"\n",
    "    \n",
    "    # Clean keywords\n",
    "    clean_keywords = clean_text(keywords)\n",
    "    \n",
    "    # Transform keywords to TF-IDF\n",
    "    keyword_vector = vectorizer.transform([clean_keywords])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = cosine_similarity(keyword_vector, job_tfidf).flatten()\n",
    "    \n",
    "    # Get top matches\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Create results\n",
    "    results = []\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        job = df_jobs.iloc[idx]\n",
    "        results.append({\n",
    "            'Rank': i + 1,\n",
    "            'Title': job['Title'],\n",
    "            'Company': job['Company'],\n",
    "            'Location': job['Location'],\n",
    "            'Similarity_Score': similarities[idx],\n",
    "            'Description': job['JobDescription'][:200] + '...' if pd.notna(job['JobDescription']) else 'N/A'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test job search\n",
    "print(\"Testing job search...\")\n",
    "search_results = search_jobs_by_keywords(\"software developer python\", df_jobs_clean, job_tfidf, vectorizer)\n",
    "print(\"\\nJob search results for 'software developer python':\")\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting results...\n",
      "\n",
      "Exported files:\n",
      "- cleaned_job_posts.csv\n",
      "- cleaned_resumes.csv\n",
      "- job_resume_matches.csv\n",
      "- job_search_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results\n",
    "print(\"Exporting results...\")\n",
    "\n",
    "# Export cleaned datasets\n",
    "df_jobs_clean.to_csv('cleaned_job_posts.csv', index=False)\n",
    "df_resumes_clean.to_csv('cleaned_resumes.csv', index=False)\n",
    "\n",
    "# Export matching results\n",
    "if 'enhanced_matches' in locals():\n",
    "    enhanced_matches.to_csv('job_resume_matches.csv', index=False)\n",
    "\n",
    "if 'search_results' in locals():\n",
    "    search_results.to_csv('job_search_results.csv', index=False)\n",
    "\n",
    "print(\"\\nExported files:\")\n",
    "print(\"- cleaned_job_posts.csv\")\n",
    "print(\"- cleaned_resumes.csv\")\n",
    "print(\"- job_resume_matches.csv\")\n",
    "print(\"- job_search_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI RECRUITMENT SYSTEM SUMMARY ===\n",
      "\n",
      "Dataset Statistics:\n",
      "- Total Job Posts: 822\n",
      "- Total Resumes: 2484\n",
      "- Resume Categories: 24\n",
      "- Unique Companies: 416\n",
      "\n",
      "System Features:\n",
      "‚úì Job posting analysis and cleaning\n",
      "‚úì Resume parsing and skill extraction\n",
      "‚úì TF-IDF based text similarity matching\n",
      "‚úì Skill-based enhanced matching\n",
      "‚úì Interactive job search by keywords\n",
      "‚úì Comprehensive analysis and visualization\n",
      "‚úì Results export to CSV\n",
      "\n",
      "Next Steps:\n",
      "1. Run individual cells to test specific features\n",
      "2. Modify matching parameters for better results\n",
      "3. Add more sophisticated ML models\n",
      "4. Create a web interface for the system\n",
      "5. Implement real-time matching API\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"=== AI RECRUITMENT SYSTEM SUMMARY ===\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"- Total Job Posts: {len(df_jobs_clean)}\")\n",
    "print(f\"- Total Resumes: {len(df_resumes_clean)}\")\n",
    "print(f\"- Resume Categories: {df_resumes_clean['Category'].nunique()}\")\n",
    "print(f\"- Unique Companies: {df_jobs_clean['Company'].nunique()}\")\n",
    "\n",
    "print(f\"\\nSystem Features:\")\n",
    "print(\"‚úì Job posting analysis and cleaning\")\n",
    "print(\"‚úì Resume parsing and skill extraction\")\n",
    "print(\"‚úì TF-IDF based text similarity matching\")\n",
    "print(\"‚úì Skill-based enhanced matching\")\n",
    "print(\"‚úì Interactive job search by keywords\")\n",
    "print(\"‚úì Comprehensive analysis and visualization\")\n",
    "print(\"‚úì Results export to CSV\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(\"1. Run individual cells to test specific features\")\n",
    "print(\"2. Modify matching parameters for better results\")\n",
    "print(\"3. Add more sophisticated ML models\")\n",
    "print(\"4. Create a web interface for the system\")\n",
    "print(\"5. Implement real-time matching API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [0] ‚Äî Chief Financial Officer | AMERIA Investment Consulting Company | Yerevan, Armenia\n",
      "\n",
      "Top 10 candidates (BERT):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Resume_ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>Resume_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17392859</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.752344</td>\n",
       "      <td>DIRECTOR OF FINANCE           Professional Summary    Seeking a position in financial/g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15891494</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.743289</td>\n",
       "      <td>FINANCE OFFICER       Summary    Profile: An experience Accountant and data base worker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14722634</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.737250</td>\n",
       "      <td>FINANCE DIRECTOR       Summary    Remarkably astute and analytical professional with ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26767199</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.730880</td>\n",
       "      <td>FINANCE MANAGER         Summary     Flexible Financial Manager with the ability to mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>38441665</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.723948</td>\n",
       "      <td>FINANCE DIRECTOR           Professional Summary     Results oriented, dependable and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>38907798</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.723342</td>\n",
       "      <td>SENIOR FINANCE MANAGER           Summary    Highly driven finance professional with ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>19234823</td>\n",
       "      <td>ADVOCATE</td>\n",
       "      <td>0.721044</td>\n",
       "      <td>FINANCE DIRECTOR       Professional Summary    To find a new and challenging position t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>88691367</td>\n",
       "      <td>CONSULTANT</td>\n",
       "      <td>0.716494</td>\n",
       "      <td>CONSULTANT           Summary    Accomplished and highly skilled Controller with a prove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>16449850</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.715431</td>\n",
       "      <td>DIRECTOR OF FINANCE         Professional Summary    Senior financial hospitality execut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>81677620</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>0.715356</td>\n",
       "      <td>FINANCE MANAGER           Summary    preparing annual budgets, monitoring key accounts ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Resume_ID    Category     Score  \\\n",
       "0     1   17392859     FINANCE  0.752344   \n",
       "1     2   15891494     FINANCE  0.743289   \n",
       "2     3   14722634     FINANCE  0.737250   \n",
       "3     4   26767199     FINANCE  0.730880   \n",
       "4     5   38441665     FINANCE  0.723948   \n",
       "5     6   38907798     FINANCE  0.723342   \n",
       "6     7   19234823    ADVOCATE  0.721044   \n",
       "7     8   88691367  CONSULTANT  0.716494   \n",
       "8     9   16449850     FINANCE  0.715431   \n",
       "9    10   81677620     FINANCE  0.715356   \n",
       "\n",
       "                                                                                           Resume_Text  \n",
       "0           DIRECTOR OF FINANCE           Professional Summary    Seeking a position in financial/g...  \n",
       "1           FINANCE OFFICER       Summary    Profile: An experience Accountant and data base worker...  \n",
       "2           FINANCE DIRECTOR       Summary    Remarkably astute and analytical professional with ov...  \n",
       "3           FINANCE MANAGER         Summary     Flexible Financial Manager with the ability to mult...  \n",
       "4           FINANCE DIRECTOR           Professional Summary     Results oriented, dependable and mo...  \n",
       "5           SENIOR FINANCE MANAGER           Summary    Highly driven finance professional with ove...  \n",
       "6           FINANCE DIRECTOR       Professional Summary    To find a new and challenging position t...  \n",
       "7           CONSULTANT           Summary    Accomplished and highly skilled Controller with a prove...  \n",
       "8           DIRECTOR OF FINANCE         Professional Summary    Senior financial hospitality execut...  \n",
       "9           FINANCE MANAGER           Summary    preparing annual budgets, monitoring key accounts ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top-10 candidates for a given job (by index or title substring)\n",
    "def top_candidates_for_job(job_index=None, title_contains=None, top_n=10):\n",
    "    # Preconditions\n",
    "    required = ['df_jobs_clean', 'df_resumes_clean']\n",
    "    for v in required:\n",
    "        if v not in globals():\n",
    "            raise RuntimeError(f\"{v} not found. Run the preprocessing cells first.\")\n",
    "    if job_index is None and not title_contains:\n",
    "        raise ValueError(\"Provide either job_index or title_contains.\")\n",
    "\n",
    "    # Pick job index\n",
    "    if job_index is None:\n",
    "        mask = df_jobs_clean['Title'].fillna('').str.contains(title_contains, case=False, na=False)\n",
    "        if not mask.any():\n",
    "            raise ValueError(f\"No job found with title containing: {title_contains}\")\n",
    "        job_index = mask.idxmax()\n",
    "\n",
    "    job_row = df_jobs_clean.iloc[job_index]\n",
    "    print(f\"Job [{job_index}] ‚Äî {job_row['Title']} | {job_row.get('Company','N/A')} | {job_row.get('Location','N/A')}\")\n",
    "\n",
    "    # Try BERT first\n",
    "    use_bert = 'find_best_matches_bert' in globals() and BERT_AVAILABLE and (bert_model is not None)\n",
    "    results = None\n",
    "\n",
    "    if use_bert:\n",
    "        try:\n",
    "            results = find_best_matches_bert(job_index, df_jobs_clean, df_resumes_clean, top_n=top_n)\n",
    "            results = results[['Rank','Resume_ID','Category','BERT_Similarity_Score','Resume_Text']]\n",
    "            results = results.rename(columns={'BERT_Similarity_Score':'Score'})\n",
    "            method = \"BERT\"\n",
    "        except Exception as e:\n",
    "            print(f\"BERT matching unavailable: {e}\")\n",
    "            results = None\n",
    "\n",
    "    # Fallback TF-IDF\n",
    "    if results is None:\n",
    "        required_tfidf = ['job_tfidf','resume_tfidf','find_best_matches']\n",
    "        if not all(r in globals() for r in required_tfidf):\n",
    "            raise RuntimeError(\"TF-IDF artifacts missing. Run the TF-IDF vectorization cell first.\")\n",
    "        results = find_best_matches(job_index, resume_tfidf, job_tfidf, df_resumes_clean, top_n=top_n)\n",
    "        results = results[['Rank','Resume_ID','Category','Similarity_Score','Resume_Text']]\n",
    "        results = results.rename(columns={'Similarity_Score':'Score'})\n",
    "        method = \"TF-IDF\"\n",
    "\n",
    "    print(f\"\\nTop {top_n} candidates ({method}):\")\n",
    "    display(results)\n",
    "    return results\n",
    "\n",
    "# Examples:\n",
    "# By index\n",
    "top10 = top_candidates_for_job(job_index=0, top_n=10)\n",
    "\n",
    "# Or by title substring\n",
    "# top10 = top_candidates_for_job(title_contains=\"data scientist\", top_n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
